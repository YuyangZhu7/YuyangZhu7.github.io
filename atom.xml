<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yarn&#39;s blog</title>
  
  
  <link href="https://yuyangzhu7.github.io/atom.xml" rel="self"/>
  
  <link href="https://yuyangzhu7.github.io/"/>
  <updated>2025-03-10T06:01:35.194Z</updated>
  <id>https://yuyangzhu7.github.io/</id>
  
  <author>
    <name>Yarn</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://yuyangzhu7.github.io/2025/03/05/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://yuyangzhu7.github.io/2025/03/05/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2025-03-05T05:13:43.992Z</published>
    <updated>2025-03-10T06:01:35.194Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="title-”图神经网络”data-2025-3-5author-”朱宇阳”"><a href="#title-”图神经网络”data-2025-3-5author-”朱宇阳”" class="headerlink" title="title:”图神经网络”data:2025-3-5author:”朱宇阳”"></a>title:”图神经网络”<br>data:2025-3-5<br>author:”朱宇阳”</h2><p>深度学习-图神经网络学习笔记,欢迎访问我的<a href="https://yuyangzhu7.github.io/">主页</a></p><span id="more"></span> <h1 id="图神经网络概述"><a href="#图神经网络概述" class="headerlink" title="图神经网络概述"></a>图神经网络概述</h1><p>随着机器学习、深度学习的发展，语音、图像、自然语言处理逐渐取得了很大的突破，然而语音、图像、文本都是很简单的序列或者网格数据，是很结构化的数据，深度学习很善于处理该种类型的数据。然而现实世界中并不是所有的事物都可以表示成一个序列或者一个网格，例如社交网络、知识图谱、复杂的文件系统等，也就是说很多事物都是非结构化的。</p><p>相比于简单的文本和图像，这种网络类型的非结构化的数据非常复杂，处理它的难点包括：</p><ul><li><p>图的大小是任意的，图的拓扑结构复杂，没有像图像一样的空间局部性</p></li><li><p>图没有固定的节点顺序，或者说没有一个参考节点</p></li><li><p>图经常是动态图，而且包含多模态的特征</p></li></ul><p>相比较于神经网络最基本的网络结构全连接层（MLP），特征矩阵乘以权重矩阵，图神经网络多了一个邻接矩阵。计算形式很简单，三个矩阵相乘再加上一个非线性变换（图3）。</p><p>  <img src="https://pic3.zhimg.com/v2-9e036b9bd672e5e396db074db214f0e8_1440w.jpg" alt="img"></p><p>  因此一个比较常见的图神经网络的应用模式如下图，输入是一个图，经过多层图卷积等各种操作以及激活函数，最终得到各个节点的表示，以便于进行节点分类、链接预测、图与子图的生成等等任务。</p><p>  <img src="https://pic2.zhimg.com/v2-19dc97280205625dcc802f9130aa66bd_1440w.jpg" alt="img"></p><h1 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h1><p>GCN的本质目的就是用来提取拓扑图的空间特征。 而图卷积神经网络主要有两类，一类是基于空间域或顶点域vertex domain(spatial domain)的，另一类则是基于频域或谱域spectral domain的。通俗点解释，空域可以类比到直接在图片的像素点上进行卷积，而频域可以类比到对图片进行<a href="https://zhida.zhihu.com/search?content_id=192209974&content_type=Article&match_order=1&q=%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2&zhida_source=entity">傅里叶变换</a>后，再进行卷积。所谓的两类其实就是从两个不同的角度理解，关于从空间角度的理解可以看本文的从空间角度理解GCN</p><h2 id="一-顶点域（空间域）"><a href="#一-顶点域（空间域）" class="headerlink" title="一.顶点域（空间域）"></a>一.顶点域（空间域）</h2><p>基于空域卷积的方法直接将卷积操作定义在每个结点的连接关系上，它跟传统的卷积神经网络中的卷积更相似一些。在这个类别中比较有代表性的方法有</p><p>这段话主要介绍了图神经网络（GNN）中一种基于<strong>空域卷积</strong>（Spatial Convolution）的核心思想及其代表性方法。以下是对这段话的逐层解析：</p><hr><h3 id="1-核心概念：空域卷积"><a href="#1-核心概念：空域卷积" class="headerlink" title="1. 核心概念：空域卷积"></a><strong>1. 核心概念：空域卷积</strong></h3><ul><li><strong>与传统卷积的区别</strong>：<ul><li>在传统卷积神经网络（CNN）中，卷积操作是<strong>固定在网格状数据</strong>（如图像、音频）上的局部模式匹配（通过滑动窗口提取特征）。例如，图像的卷积核会在像素的二维平面上滑动。</li><li><strong>空域卷积</strong>则针对<strong>图结构数据</strong>（非欧几里得空间），将卷积操作直接定义在<strong>节点的连接关系</strong>（即图的邻接关系）上。它的核心是<strong>聚合节点及其邻居的信息</strong>，而非固定窗口内的像素。</li></ul></li><li><strong>关键特点</strong>：<ul><li><strong>动态邻域</strong>：每个节点的“感受野”由其邻居决定，而非固定的网格位置。</li><li><strong>图同构不变性</strong>：卷积操作能适应图的拓扑结构变化（如不同形状的分子结构）。</li></ul></li></ul><hr><h3 id="2-典型方法：空域卷积的代表模型"><a href="#2-典型方法：空域卷积的代表模型" class="headerlink" title="2. 典型方法：空域卷积的代表模型"></a><strong>2. 典型方法：空域卷积的代表模型</strong></h3><p>以下方法均通过不同的方式实现了空域卷积的思想：</p><h4 id="1-Message-Passing-Neural-Networks-MPNN-1"><a href="#1-Message-Passing-Neural-Networks-MPNN-1" class="headerlink" title="(1) Message Passing Neural Networks (MPNN) [1]"></a><strong>(1) Message Passing Neural Networks (MPNN)</strong> [1]</h4><ul><li>思想：明确提出了消息传递框架（Message Passing），将节点间的信息交互建模为两步：<ol><li><strong>消息传递</strong>：节点将自己的特征与邻居的特征结合，生成新的消息。</li><li><strong>聚合</strong>：节点将接收到的所有邻居的消息进行聚合（如求和、均值），更新自身特征。</li></ol></li><li><strong>优势</strong>：提供了统一的图神经网络建模范式，被许多后续研究继承（如GCN）。</li></ul><h4 id="2-GraphSAGE-2"><a href="#2-GraphSAGE-2" class="headerlink" title="(2) GraphSAGE [2]"></a><strong>(2) GraphSAGE</strong> [2]</h4><ul><li>思想：采用归纳式学习（Inductive Learning），通过聚合节点的局部邻居信息生成节点嵌入。其核心步骤包括：<ol><li>节点采样邻居（如随机选取固定数量的邻居）。</li><li>聚合邻居特征并更新当前节点表示。</li></ol></li><li><strong>优势</strong>：<br>计算高效，支持大规模图的训练（如社交网络）。</li></ul><h4 id="3-Diffusion-Convolution-Neural-Networks-DCNN-3"><a href="#3-Diffusion-Convolution-Neural-Networks-DCNN-3" class="headerlink" title="(3) Diffusion Convolution Neural Networks (DCNN) [3]"></a><strong>(3) Diffusion Convolution Neural Networks (DCNN)</strong> [3]</h4><ul><li><strong>思想</strong>：<br>将卷积操作与<strong>扩散过程</strong>​（Diffusion Process）结合。通过多轮扩散（类似热传导），将节点的局部信息逐步传播到整个图，形成全局感知的特征。</li><li><strong>数学形式</strong>：<br>使用图的拉普拉斯矩阵的幂次（<em>L**k</em>）对节点特征进行变换，隐式地模拟了信息扩散的步数 <em>k</em>。</li><li><strong>优势</strong>：<br>明确关联了卷积操作与图的谱分解（频域方法），但计算成本较高。</li></ul><h4 id="4-PATCHY-SAN-4"><a href="#4-PATCHY-SAN-4" class="headerlink" title="(4) PATCHY-SAN [4]"></a><strong>(4) PATCHY-SAN</strong> [4]</h4><ul><li>思想：将图划分为若干个小块（PATCHES），并在每个小块内应用类似于CNN的局部卷积操作。具体步骤：<ol><li>对图进行超图划分，提取节点及其邻居组成的子图（PATCH）。</li><li>在每个PATCH内对节点特征进行卷积（如权重共享的全连接层）。</li><li>汇总所有PATCH的结果生成全局特征。</li></ol></li><li><strong>优势</strong>：<br>直接复用CNN的成熟架构，增强了对局部结构的建模能力。</li></ul><p><img src="file:///C:\Users\朱宇阳\AppData\Local\Temp\ksohtml8804\wps1.jpg" alt="img"> </p><h2 id="二-spectral-domain：频域方法（谱方法）"><a href="#二-spectral-domain：频域方法（谱方法）" class="headerlink" title="二. spectral domain：频域方法（谱方法）"></a>二. spectral domain：频域方法（谱方法）</h2><p>这就是谱域图卷积网络的理论基础了。这种思路就是希望借助图谱的理论来实现拓扑图上的卷积操作。从整个研究的时间进程来看：首先研究GSP（graph signal processing）的学者定义了graph上的Fourier Transformation，进而定义了graph上的convolution，最后与深度学习结合提出了Graph Convolutional Network。</p><p>基于频域卷积的方法则从<a href="https://zhida.zhihu.com/search?content_id=192209974&content_type=Article&match_order=1&q=%E5%9B%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86&zhida_source=entity">图信号处理</a>起家，包括 Spectral CNN[5], Cheybyshev Spectral CNN(ChebNet)[6], 和 First order of ChebNet(1stChebNet)[7]　等。论文Semi-Supervised Classification with Graph Convolutional Networks就是一阶邻居的ChebNet。认真读到这里，脑海中应该会浮现出一系列问题：</p><h3 id="1-基础导引"><a href="#1-基础导引" class="headerlink" title="1.基础导引"></a>1.基础导引</h3><p><strong>Q1 什么是</strong><a href="https://zhida.zhihu.com/search?content_id=192209974&content_type=Article&match_order=1&q=Spectral+graph+theory&zhida_source=entity"><strong>Spectral graph theory</strong></a><strong>？</strong></p><p>Spectral graph theory请参考维基百科的介绍，简单的概括就是借助于图的<a href="https://zhida.zhihu.com/search?content_id=192209974&content_type=Article&match_order=1&q=%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5&zhida_source=entity">拉普拉斯矩阵</a>的特征值和特征向量来研究图的性质</p><p><strong>Q2 GCN为什么要利用Spectral graph theory？</strong>这是论文（<strong>Semi-Supervised Classification with Graph Convolutional Networks</strong>）中的重点和难点，要理解这个问题需要大量的数学定义及推导</p><p>过程：</p><p>（1）定义graph上的Fourier Transformation傅里叶变换（利用Spectral graph theory，借助图的拉普拉斯矩阵的特征值和特征向量研究图的性质）</p><p>（2）定义graph上的convolution卷积</p><h2 id="三-频域方法下图卷积网络的推导"><a href="#三-频域方法下图卷积网络的推导" class="headerlink" title="三.频域方法下图卷积网络的推导"></a>三.频域方法下图卷积网络的推导</h2><h3 id="1-拉普拉斯矩阵"><a href="#1-拉普拉斯矩阵" class="headerlink" title="1.拉普拉斯矩阵"></a>1.拉普拉斯矩阵</h3><p> 拉普拉斯矩阵，主要应用在图论中，作为一个图的矩阵表示。对于图 G&#x3D;(V,E)，其Laplacian 矩阵的定义为 L&#x3D;D-A，</p><blockquote><p>其中 L 是Laplacian 矩阵，D&#x3D;diag(d)是顶点的度矩阵,对角线上元素依次为各个顶点的度，<br>A 是图的邻接矩阵。 频域卷积的前提条件是图必须是无向图，只考虑无向图，那么L就是对称矩阵。 </p></blockquote><p> <img src="https://pica.zhimg.com/v2-8bb65d0bfb5f9efc2d9d791fbb548a9c_r.jpg" alt="img"> </p><p><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741093107548.png" alt="1741093107548" style="zoom: 67%;" /><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741093130383.png" alt="1741093130383"></p><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741093130383.png" alt="1741093130383" style="zoom:70%;" /><p>（1）拉普拉斯矩阵是半正定矩阵。（最小特征值大于等于0）</p><p>（2）特征值中0出现的次数就是图连通区域的个数。</p><p>（3）最小特征值是0，因为拉普拉斯矩阵（普通形式： $L&#x3D;D−A$）每一行的和均为0，并且最小特征值对应的特征向量是每个值全为1的向量；</p><p>（4）最小非零特征值是图的代数连通度。</p><p>要证明拉普拉斯矩阵是半正定的，只需要证明其二次型$ f^{T} L f \geq 0 $证明：<br>$$<br>\begin{aligned}f^{T} L f &amp;&#x3D;f^{T} D f-f^{T} A f \&amp;&#x3D;f^{T} * \operatorname{diag}(d) * f-f^{T} A f \&amp;&#x3D;\sum_{i&#x3D;1}^{m} d_{i} f_{i}^{2}-\sum_{j&#x3D;1}^{m}\left[\sum_{i&#x3D;1}^{m} f_{j} * a_{i j}\right] f_{j} \&amp;&#x3D;\sum_{i&#x3D;1}^{m} d_{i} f_{i}^{2}-\sum_{i, j&#x3D;1}^{m} f_{i} * f_{j} * a_{i j} \&amp;&#x3D;\frac{1}{2}\left[\sum_{i&#x3D;1}^{m} d_{i} f_{i}^{2}-2 \sum_{i, j&#x3D;1}^{m} f_{i} f_{j} a_{i j}+\sum_{j&#x3D;1}^{m} d_{j} f_{j}^{2}\right] \&amp;&#x3D;\frac{1}{2} \sum_{i, j&#x3D;1}^{m} a_{i j}\left(f_{i}-f_{j}\right)^{2}\end{aligned}<br>$$<br>所以，对于任意一个属于实向量fff都有此公式成立。</p><p> <strong>特征分解，又称谱分解</strong>是将<strong>矩阵分解为由其特征值和特征向量表示的矩阵之积的方法</strong>。只有对可对角化矩阵或有n个线性无关的特征向量的矩阵才可以施以特征分解。   不是所有的矩阵都可以特征分解，其充要条件为n阶方阵存在n个线性无关的特征向量。 </p><p><strong>拉普拉斯矩阵是半正定矩阵（半正定矩阵本身就是对称矩阵），有如下三个性质：</strong></p><ul><li>对称矩阵一定n个线性无关的特征向量</li><li>半正定矩阵的特征值一定非负</li><li>对阵矩阵的不同特征值对应的特征向量相互正交，这些正交的特征向量构成的矩阵为正交矩阵。<br>由上拉普拉斯矩阵对称知一定可以谱分解，且分解后有特殊的形式。</li></ul><p>对于拉普拉斯矩阵其谱分解为：</p><p>$L&#x3D;U \Lambda U^{-1}&#x3D;U \Lambda U^{-1}&#x3D;U\left[\begin{array}{lll}\lambda_{1} &amp; &amp; &amp; \&amp; &amp; \ddots &amp; \&amp; &amp; \lambda_{n}\end{array}\right] U^{-1}$</p><p>其中$U&#x3D;\left(\vec{u}<em>{1}, \vec{u}</em>{2}, \cdots, \overrightarrow{u_{n}}\right),$ 是列向量为单位特征向量的矩阵, 也就说 $\vec{u_1}$ 是列向量,$\wedge $是n个特征值构成的对角阵。由于 $U$正交矩阵, 即 $U U^{T}&#x3D;E$, 所以特征分解又可以写成:$L&#x3D;U \Lambda U^{-1}&#x3D;U \Lambda U^{T}$</p><h3 id="2-拉普拉斯算子"><a href="#2-拉普拉斯算子" class="headerlink" title="2. 拉普拉斯算子"></a>2. 拉普拉斯算子</h3><p>定义：拉普拉斯算子是n维欧几里德空间中的一个二阶微分算子，定义为<strong>梯度 (∇f)(\nabla f)$(\nabla f) $的散度</strong> (∇⋅f(\nabla \cdot f(\nabla \cdot f, 即 ∇f⋅f)\nabla f \cdot f)\nabla f $\cdot f) $。因此如果fff是二阶可微的实函数，则的拉普拉斯算子 Δ\Delta\Delta 定义为:</p><p>$$\Delta f&#x3D;\nabla^{2} f&#x3D;\nabla \cdot \nabla f$$</p><p>fff的拉普拉斯算子也是笛卡尔坐标系xix_ix_i中的所有非混合二阶偏导数：</p><p>$\Delta f&#x3D;\sum_{i&#x3D;1}^{n} \frac{\partial^{2} f}{\partial x_{i}^{2}}$</p><p>函数的拉普拉斯算子也是该函数的黑塞矩阵(是一个多元函数的二阶偏导数构成的方阵)的迹:</p><p>$\Delta f&#x3D;\operatorname{tr}(H(f))$</p><p><strong>拉普拉斯算子(Laplacian operator) 的物理意义是空间二阶导</strong>, 准确定义是：<strong>标量梯度场中的散度</strong>, 一般可用于描述物理量的流入流出。 比如说在二维空间中的温度传播规律，一般可以用拉普拉斯算子来描述。</p><h3 id="3-离散形式的一维卷积"><a href="#3-离散形式的一维卷积" class="headerlink" title="3. 离散形式的一维卷积"></a>3. 离散形式的一维卷积</h3><p>对于定义在整数 $\mathbb{Z} $上的函数 $\mathrm{g}$, 卷积定义为</p><p>$ (f * g)(t)&#x3D;\sum_{\tau&#x3D;-\infty}^{\infty} f(\tau) g(t-\tau)$</p><p>所谓卷积，其实就是<strong>把一个函数卷(翻)过来，然后与另一个函数求内积</strong>。</p><p>对应到不同方面，<strong>卷积</strong>可以有不同的解释：**g 既可以看作我们在深度学习里常说的核(Kernel)，也可以对应到信号处理中的滤波器(Filter)**。而 f 可以是我们所说的机器学习中的特征(Feature)，也可以是信号处理中的信号(Signal)。f和g的卷积 (f∗g)就可以看作是对f的加权求和。下面两个动图就分别对应信号处理与深度学习中卷积操作的过程。</p><p> <img src="https://picx.zhimg.com/v2-15fea61b768f7561648dbea164fcb75f_b.webp" alt="动图"> </p><h3 id="4-傅里叶变换"><a href="#4-傅里叶变换" class="headerlink" title="4. 傅里叶变换"></a>4. 傅里叶变换</h3><h4 id="4-1-连续形式的傅立叶变换"><a href="#4-1-连续形式的傅立叶变换" class="headerlink" title="4.1 连续形式的傅立叶变换"></a>4.1 连续形式的傅立叶变换</h4><h5 id="4-1-1-如何直观地理解傅立叶变换？"><a href="#4-1-1-如何直观地理解傅立叶变换？" class="headerlink" title="4.1.1 如何直观地理解傅立叶变换？"></a>4.1.1 如何直观地理解傅立叶变换？</h5><p> 傅里叶级数：任何周期函数，只要满足一定条件都可以表示为不同频率的正弦和&#x2F;或余弦之和的形式，该和成为傅里叶级数。</p><p>傅里叶变换：任何非周期函数（但该曲线下的面积是有限的），也可以用正弦和&#x2F;或余弦乘以加权函数的积分来表示，在这种情况下的公式就是傅里叶变换。</p><p>傅里叶级数与傅里叶变换的关系：周期函数的周期可以趋向无穷大，这样就可以将傅里叶变换看成是傅里叶级数的推广。</p><h4 id="4-2傅里叶级数与傅里叶变换"><a href="#4-2傅里叶级数与傅里叶变换" class="headerlink" title="4.2傅里叶级数与傅里叶变换"></a>4.2傅里叶级数与傅里叶变换</h4><h5 id="4-2-1-傅里叶级数的三角形式"><a href="#4-2-1-傅里叶级数的三角形式" class="headerlink" title="4.2.1 傅里叶级数的三角形式"></a>4.2.1 傅里叶级数的三角形式</h5><p>假设 $f(x)$ 是周期为 $T$ 的函数，并且满足傅里叶级数的收敛条件，那么可以写作傅里叶级数：</p><p>$$<br>f(x) &#x3D; \frac{a_0}{2} + \sum_{n&#x3D;1}^{+\infty} \left( a_n \cos \frac{2 \pi n x}{T} + b_n \sin \frac{2 \pi n x}{T} \right)<br>$$</p><p>其中，系数 $a_0$、$a_n$ 和 $b_n$ 的计算公式为：</p><p>$$<br>\begin{gathered}<br>a_0 &#x3D; \frac{2}{T} \int_{x_0}^{x_0 + T} f(x) , dx \<br>a_n &#x3D; \frac{2}{T} \int_{x_0}^{x_0 + T} f(x) \cos \left( \frac{2 \pi n x}{T} \right) dx \<br>b_n &#x3D; \frac{2}{T} \int_{x_0}^{x_0 + T} f(x) \sin \left( \frac{2 \pi n x}{T} \right) dx<br>\end{gathered}<br>$$</p><p>• $a_0$：表示函数 $f(x)$ 的平均值。<br>• $a_n$ 和 $b_n$：分别表示余弦和正弦分量的权重。</p><h5 id="4-2-2-傅里叶级数的复指数形式"><a href="#4-2-2-傅里叶级数的复指数形式" class="headerlink" title="4.2.2 傅里叶级数的复指数形式"></a>4.2.2 傅里叶级数的复指数形式</h5><p>借助欧拉公式，可以将傅里叶级数的三角形式转换为复指数形式：</p><p>$$<br>f(x) &#x3D; \sum_{n&#x3D;-\infty}^{+\infty} c_n e^{i \frac{2 \pi n x}{T}}<br>$$</p><p>其中，系数 $c_n$ 的计算公式为：</p><p>$$<br>c_n &#x3D; -\frac{1}{T} \int_{-\frac{F}{2}}^{\frac{\tau}{2}} f(x) e^{-i \frac{2 \pi n x}{T}} dx<br>$$</p><p><strong>解释</strong>：<br>• 曲线可以理解为无数旋转的叠加，将 $f(x)$ 看作是圆周运动的组合。<br>• $x$ 的不断增大称为<strong>时域</strong>。</p><hr><h4 id="4-3、傅里叶变换"><a href="#4-3、傅里叶变换" class="headerlink" title="4.3、傅里叶变换"></a>4.3、傅里叶变换</h4><h5 id="4-3-1-一维连续傅里叶变换"><a href="#4-3-1-一维连续傅里叶变换" class="headerlink" title="4.3.1 一维连续傅里叶变换"></a>4.3.1 一维连续傅里叶变换</h5><p>对于定义域为整个时间轴（$-\infty &lt; t &lt; +\infty$）的非周期函数 $f(x)$，无法通过周期拓延将其扩展为周期函数，此时需要用到傅里叶变换：</p><p>$$<br>F(u) &#x3D; \int_{-\infty}^{+\infty} f(x) e^{-i 2 \pi u x} dx<br>$$</p><p>其中：<br>• $F(u)$ 是 $f(x)$ 的频域表示。<br>• $u$ 是频率，单位为 $1&#x2F;T$。</p><p>根据傅里叶反变换公式，可以从频域恢复到时域：</p><p>$$<br>f(x) &#x3D; \int_{-\infty}^{+\infty} F(u) e^{i 2 \pi u x} du<br>$$</p><h5 id="4-3-2-傅里叶变换与傅里叶级数的关系"><a href="#4-3-2-傅里叶变换与傅里叶级数的关系" class="headerlink" title="4.3.2 傅里叶变换与傅里叶级数的关系"></a>4.3.2 傅里叶变换与傅里叶级数的关系</h5><p>• <strong>对比</strong>：<br>  • 傅里叶级数中的 $a_n$ 和 $b_n$ 是离散的频域系数，而傅里叶变换的结果 $F(u)$ 是连续的频域表示。<br>  • 傅里叶级数是对周期函数的分解，而傅里叶变换适用于非周期函数。</p><p>• <strong>频率的连续化</strong>：<br>  • 当周期 $T \to +\infty$ 时，频率 $u &#x3D; 1&#x2F;T$ 趋近于连续变化，因此离散的求和变为积分形式。</p><p><strong>总结</strong>：<br>• 傅里叶变换的结果 $F(u)$ 实际上相当于傅里叶级数展开中的傅里叶系数。<br>• 傅里叶反变换公式体现了不同频率复指数函数的加权和形式，只不过这里的频率 $u$ 是连续的，因此采用了积分的形式。</p><p>$$<br>h_v &#x3D; f\left(\frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} W x_u + b\right) \quad \forall v \in \mathcal{V}<br>$$<br><strong>1. 符号解释</strong></p><p><strong>节点和邻居</strong><br>• $\mathcal{V}$：图中的所有节点集合。<br>• $\mathcal{N}(v)$：节点 $v$ 的邻居节点集合。<br>• $|\mathcal{N}(v)|$：节点 $v$ 的邻居节点数量（即邻居集合的大小）。</p><p><strong>特征表示</strong><br>• $x_u$：节点 $u$ 的特征向量，通常是一个 $d$ 维向量。<br>• $W$：可学习的权重矩阵，维度为 $d \times d’$，用于对节点特征进行线性变换。<br>• $b$：可学习的偏置向量，维度为 $d’$。</p><p><strong>聚合与变换</strong><br>• $\sum_{u \in \mathcal{N}(v)}$：对节点 $v$ 的所有邻居节点 $u$ 的特征进行求和。<br>• $\frac{1}{|\mathcal{N}(v)|}$：对邻居节点的特征求和结果进行归一化，确保聚合结果的值与邻居数量无关。</p><p><strong>输出特征</strong><br>• $h_v$：节点 $v$ 的输出特征向量，经过聚合和变换后得到。<br>• $f(\cdot)$：激活函数（如 ReLU），用于引入非线性。</p><p><strong>2. 公式的含义</strong><br>这个公式描述了 GCN Layer 的核心操作，主要包括以下几个步骤：</p><p><strong>(1) 邻居特征的聚合</strong><br>$$<br>\sum_{u \in \mathcal{N}(v)} x_u<br>$$<br>• 对节点 $v$ 的所有邻居节点 $u$ 的特征向量 $x_u$ 进行求和。<br>• 这一步的目的是捕捉节点 $v$ 的局部结构信息，即通过邻居节点的特征来更新节点 $v$ 的表示。</p><p><strong>(2) 归一化</strong><br>$$<br>\frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} x_u<br>$$<br>• 将邻居节点的特征求和结果除以邻居节点的数量 $|\mathcal{N}(v)|$，进行归一化。<br>• 归一化的目的是避免节点特征的聚合结果受到邻居数量的影响。例如，某些节点可能有很多邻居，而另一些节点可能只有很少的邻居。</p><p><strong>(3) 线性变换</strong><br>$$<br>W \cdot \left(\frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} x_u\right) + b<br>$$<br>• 对归一化后的邻居特征进行线性变换：<br>  • $W$ 是可学习的权重矩阵，用于将输入特征映射到新的特征空间。<br>  • $b$ 是可学习的偏置向量，用于调整特征的偏移。<br>• 这一步的目的是让模型能够学习到更复杂的特征表示。</p><p><strong>(4) 非线性激活</strong><br>$$<br>f\left(W \cdot \left(\frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} x_u\right) + b\right)<br>$$<br>• 对线性变换的结果应用激活函数 $f(\cdot)$（如 ReLU），引入非线性。<br>• 非线性的引入使得模型能够捕捉更复杂的图结构信息。</p><p><strong>(5) 输出特征</strong><br>$$<br>h_v &#x3D; f\left(\frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} W x_u + b\right)<br>$$<br>• 最终得到节点 $v$ 的输出特征 $h_v$，它是节点 $v$ 及其邻居节点特征的聚合结果，经过线性变换和非线性激活后的表示。</p><p><strong>3. 公式的特点</strong><br><strong>(1) 局部性</strong><br>• 该公式只考虑了节点 $v$ 的直接邻居节点的特征，而没有考虑更远的节点。这种局部性使得 GCN 能够捕捉图的局部结构信息。</p><p><strong>(2) 归一化</strong><br>• 通过 $\frac{1}{|\mathcal{N}(v)|}$ 的归一化操作，确保了不同节点的特征聚合结果不会因为邻居数量的差异而产生偏差。</p><p><strong>(3) 可学习性</strong><br>• 权重矩阵 $W$ 和偏置向量 $b$ 是可学习的，模型能够通过训练自动调整这些参数，从而适应不同的图结构和任务。</p><p><strong>(4) 非线性</strong><br>• 激活函数 $f(\cdot)$ 的引入使得模型能够捕捉非线性的图结构特征。</p><p><strong>4. 公式的改进与扩展</strong><br>在实际应用中，GCN 的公式可能会有一些改进和扩展，例如：<br><strong>(1) ChebNet（切比雪夫多项式近似）</strong><br>• 使用切比雪夫多项式来近似拉普拉斯矩阵的特征值分解，从而减少计算复杂度。<br>• 公式形式为：<br>$$<br>  h_v &#x3D; f\left(\sum_{k&#x3D;0}^K \theta_k T_k(\tilde{L}) x_v\right)<br>$$<br>  其中 $T_k(\cdot)$ 是切比雪夫多项式，$\tilde{L}$ 是归一化的拉普拉斯矩阵。</p><p><strong>(2) GraphSAGE</strong><br>• 在 GCN 的基础上引入了采样机制，支持大规模图的训练。<br>• 公式形式与 GCN 类似，但邻居节点的选择是动态的。</p><p><strong>(3) 无归一化的 GCN</strong><br>• 在某些情况下，可能会去掉归一化项 $\frac{1}{|\mathcal{N}(v)|}$，直接对邻居特征求和：<br>$$<br>  h_v &#x3D; f\left(\sum_{u \in \mathcal{N}(v)} W x_u + b\right)<br>$$</p><p>这段文字主要介绍了 <strong>GraphSAGE</strong> 的背景、动机以及其核心思想，特别是它如何解决 <strong>GCN</strong> 的两个主要缺点，并引入了 <strong>Inductive Learning</strong> 和 <strong>Transductive Learning</strong> 的概念。以下是对这段文字的逐层解读：</p><hr><h2 id="GCN的两个缺点"><a href="#GCN的两个缺点" class="headerlink" title="GCN的两个缺点"></a><strong>GCN的两个缺点</strong></h2><p>在介绍 GraphSAGE 之前，先明确 GCN 的两个主要缺点：</p><ol><li><p><strong>Transductive Learning（传导学习）</strong>：<br>• GCN 在训练时需要输入整个图，包括训练集、验证集和测试集的所有节点。<br>• 在训练过程中，GCN 会利用所有节点的邻居信息来更新节点的表示，这意味着测试集和验证集的节点信息也会被用来训练模型。<br>• 这种方式限制了 GCN 的泛化能力，因为它无法处理图中<strong>新加入的节点</strong>。</p></li><li><p><strong>无法处理动态图</strong>：<br>• GCN 的训练依赖于整个图的拓扑结构，因此当图中加入新节点或边时，需要重新训练整个模型。</p></li></ol><h3 id="1-Inductive-Learning-和-Transductive-Learning"><a href="#1-Inductive-Learning-和-Transductive-Learning" class="headerlink" title="1. Inductive Learning 和 Transductive Learning"></a><strong>1. Inductive Learning 和 Transductive Learning</strong></h3><p>为了更好地理解 GraphSAGE 的动机，需要先了解 <strong>Inductive Learning（归纳学习）</strong> 和 <strong>Transductive Learning（传导学习）</strong> 的区别：</p><h4 id="1-Transductive-Learning"><a href="#1-Transductive-Learning" class="headerlink" title="(1) Transductive Learning"></a><strong>(1) Transductive Learning</strong></h4><p>• <strong>定义</strong>：在训练过程中，模型会看到所有的样本（包括训练集、验证集和测试集），并通过这些样本之间的关系（如图中的边）来学习节点的表示。<br>• <strong>GCN 的问题</strong>：<br>  • GCN 是一个典型的 Transductive Learning 模型。<br>  • 在训练时，GCN 会利用测试集和验证集的节点信息来更新训练集节点的表示，这会导致模型在测试集上的表现可能过于依赖训练时的特定图结构。</p><h4 id="2-Inductive-Learning"><a href="#2-Inductive-Learning" class="headerlink" title="(2) Inductive Learning"></a><strong>(2) Inductive Learning</strong></h4><p>• <strong>定义</strong>：在训练过程中，模型只使用训练样本，训练样本和测试样本是完全分离的。<br>• <strong>GraphSAGE 的优势</strong>：<br>  • GraphSAGE 是一个 Inductive Learning 框架。<br>  • 在训练时，GraphSAGE 只使用训练样本的节点信息，而不需要访问测试集或验证集的节点。<br>  • 这种方式使得 GraphSAGE 能够处理动态图，并且可以为图中新加入的节点生成嵌入（embedding）。</p><h1 id="GraphSAGE-的核心思想"><a href="#GraphSAGE-的核心思想" class="headerlink" title="GraphSAGE 的核心思想"></a>GraphSAGE 的核心思想</h1><p>GraphSAGE 是为了解决 GCN 的上述问题而提出的，它的核心思想是<strong>归纳学习</strong>，即通过已知节点的信息为未知节点生成嵌入。</p><h2 id="1-关键步骤"><a href="#1-关键步骤" class="headerlink" title="1.关键步骤"></a>1.关键步骤</h2><p>以下是 GraphSAGE 的两个关键步骤：</p><h3 id="1-Sample（采样）"><a href="#1-Sample（采样）" class="headerlink" title="(1) Sample（采样）"></a><strong>(1) Sample（采样）</strong></h3><p>• <strong>问题</strong>：<br>  • 在图数据中，每个节点的邻居数量可能非常不均衡。例如，某些节点可能有成百上千个邻居，而另一些节点可能只有几个邻居。<br>  • 如果直接对所有邻居进行聚合，计算成本会非常高，尤其是当图的规模很大时。<br>• <strong>解决方法</strong>：<br>  • GraphSAGE 提出了<strong>邻居采样</strong>的方法，即在每次更新节点表示时，只随机选择一部分邻居节点进行聚合。<br>  • 这种方式显著降低了计算复杂度，同时仍然能够捕捉到图的全局结构信息。</p><h3 id="2-Aggregate（聚合）"><a href="#2-Aggregate（聚合）" class="headerlink" title="(2) Aggregate（聚合）"></a><strong>(2) Aggregate（聚合）</strong></h3><p>• <strong>问题</strong>：<br>  • 在聚合邻居节点的信息时，需要设计一种有效的机制来将这些邻居的嵌入信息整合到当前节点的表示中。<br>• <strong>解决方法</strong>：<br>  • GraphSAGE 提出了多种聚合函数（Aggregator），包括：<br>    1. <strong>均值聚合（Mean Aggregator）</strong>：<br>       ◦ 将邻居节点的嵌入取均值，作为当前节点的聚合结果。<br>        2. <strong>池化聚合（Pooling Aggregator）</strong>：<br>       ◦ 对邻居节点的嵌入进行池化操作（如最大池化、平均池化），以捕捉邻居节点的重要特征。<br>            3. <strong>LSTM 聚合（LSTM Aggregator）</strong>：<br>       ◦ 使用 LSTM 模型对邻居节点的嵌入进行序列建模，从而捕捉邻居节点的顺序信息。<br>                4. <strong>注意力机制聚合（Attention Aggregator）</strong>：<br>       ◦ 使用注意力机制为每个邻居节点分配不同的权重，从而更灵活地聚合邻居信息。</p><h2 id="2-GraphSAGE-的训练过程"><a href="#2-GraphSAGE-的训练过程" class="headerlink" title="2. GraphSAGE 的训练过程"></a><strong>2. GraphSAGE 的训练过程</strong></h2><p>GraphSAGE 的训练过程可以总结为以下几个步骤：</p><ol><li><strong>采样邻居节点</strong>：<br>• 对每个节点，随机采样一定数量的邻居节点。</li><li><strong>聚合邻居信息</strong>：<br>• 使用某种聚合函数（如均值、池化、LSTM 或注意力）将邻居节点的嵌入信息整合到当前节点的表示中。</li><li><strong>更新节点表示</strong>：<br>• 将聚合后的邻居信息与当前节点的特征进行结合（通常通过线性变换和非线性激活），生成新的节点表示。</li><li><strong>预测与优化</strong>：<br>• 使用生成的节点表示进行预测（如节点分类、链接预测等），并通过误差反向传播优化模型参数。</li></ol><h2 id="3-GraphSAGE-的优点"><a href="#3-GraphSAGE-的优点" class="headerlink" title="3. GraphSAGE 的优点"></a><strong>3. GraphSAGE 的优点</strong></h2><p>GraphSAGE 相较于 GCN 有以下几个显著优点：</p><ol><li><strong>Inductive Learning</strong>：<br>• GraphSAGE 是一个归纳学习框架，能够处理图中新加入的节点，而不需要重新训练整个模型。</li><li><strong>动态图支持</strong>：<br>• GraphSAGE 可以处理动态图，适应图中节点和边的变化。</li><li><strong>可扩展性</strong>：<br>• 通过邻居采样，GraphSAGE 显著降低了计算复杂度，适合大规模图数据。</li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a><strong>4. 总结</strong></h2><p>• <strong>GCN 的局限性</strong>：<br>  • GCN 是一个传导学习模型，训练时需要访问整个图，无法处理动态图和新加入的节点。<br>• <strong>GraphSAGE 的创新</strong>：<br>  • GraphSAGE 是一个归纳学习框架，通过邻居采样和聚合机制，能够高效地为图中新加入的节点生成嵌入。<br>• <strong>GraphSAGE 的核心</strong>：<br>  • <strong>Sample</strong>：对邻居节点进行采样。<br>  • <strong>Aggregate</strong>：聚合邻居节点的信息。</p><p>如果需要进一步探讨 GraphSAGE 的具体实现或与其他图神经网络模型的对比，请随时告诉我！</p><h3 id="公式结构"><a href="#公式结构" class="headerlink" title="公式结构"></a><strong>公式结构</strong></h3><p>$$<br>\alpha_{i,j} &#x3D; \frac{\exp\left(\text{LeakyReLU}\left(\vec{a}^T [W\vec{h}_i | W\vec{h}<em>j]\right)\right)}{\sum</em>{k \in N_i} \exp\left(\text{LeakyReLU}\left(\vec{a}^T [W\vec{h}_i | W\vec{h}_k]\right)\right)}<br>$$</p><h4 id="关键步骤解析"><a href="#关键步骤解析" class="headerlink" title="关键步骤解析"></a><strong>关键步骤解析</strong></h4><ol><li><p><strong>线性变换（共享权重）</strong><br>• 每个节点 $i$ 和其邻居节点 $j$ 的原始特征 $\vec{h}_i$ 和 $\vec{h}_j$ 通过共享的权重矩阵 $W$ 进行线性变换，得到 $W\vec{h}_i$ 和 $W\vec{h}_j$。<br>• <strong>作用</strong>：将原始特征映射到高维空间，增强表达能力。</p></li><li><p><strong>拼接与注意力得分计算</strong><br>• 将变换后的特征拼接为 $[W\vec{h}_i | W\vec{h}_j]$（维度从 $d$ 变为 $2d$）。<br>• 通过可学习的参数向量 $\vec{a}$（维度 $2d$）与拼接向量做点积，得到标量注意力得分：<br>$$<br>  \text{Score}(i,j) &#x3D; \vec{a}^T [W\vec{h}_i | W\vec{h}_j]<br>$$<br>• <strong>作用</strong>：衡量节点 $i$ 和 $j$ 之间的相关性。</p></li><li><p><strong>非线性激活与归一化</strong><br>• 对得分应用 <strong>LeakyReLU</strong> 激活函数（允许负值输入，缓解梯度消失）。<br>• 通过 <strong>Softmax</strong> 归一化：<br>$$<br>  \alpha_{i,j} &#x3D; \frac{\exp(\text{LeakyReLU}(\text{Score}(i,j)))}{\sum_{k \in N_i} \exp(\text{LeakyReLU}(\text{Score}(i,k)))}<br>$$<br>• <strong>作用</strong>：归一化权重，使 $\sum_{j \in N_i} \alpha_{i,j} &#x3D; 1$。</p></li></ol><h3 id="关键点说明"><a href="#关键点说明" class="headerlink" title="关键点说明"></a><strong>关键点说明</strong></h3><ol><li><p><strong>共享参数</strong><br>• 权重矩阵 $W$ 和参数向量 $\vec{a}$ <strong>对所有节点共享</strong>，减少参数量并增强模型泛化能力。</p></li><li><p><strong>分母修正</strong><br>• 原公式分母可能存在笔误，正确的求和项应为 $\sum_{k \in N_i} \exp(\text{LeakyReLU}(\vec{a}^T [W\vec{h}_i | W\vec{h}_k]))$，即用 $k$ 替换 $j$，确保归一化时遍历所有邻居节点。</p></li><li><p><strong>注意力机制的优势</strong><br>• 动态分配权重：根据节点特征自适应学习连接重要性，优于预定义的图结构权重（如邻接矩阵）。<br>• 局部性：仅计算节点与其邻居的权重，复杂度为 $O(|E|)$，适合大规模图数据。</p></li></ol><h3 id="示例计算"><a href="#示例计算" class="headerlink" title="示例计算"></a><strong>示例计算</strong></h3><p>假设节点 $i$ 的邻居为 ${j, k, l}$，特征维度 $d&#x3D;2$，则计算过程如下：</p><ol><li>对每个邻居 $j, k, l$，计算 $W\vec{h}_i$ 和 $W\vec{h}_j$，并拼接为 $4$ 维向量。  </li><li>通过 $\vec{a}^T$ 计算得分，应用 LeakyReLU。  </li><li>对得分取指数并归一化：<br>$$<br>\alpha_{i,j} &#x3D; \frac{\exp(s_{i,j})}{\exp(s_{i,j}) + \exp(s_{i,k}) + \exp(s_{i,l})}<br>$$</li></ol><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a><strong>应用场景</strong></h3><p>该公式用于图注意力网络的 <strong>消息传递</strong> 阶段，节点 $i$ 的新特征为其邻居特征的加权和：<br>$$<br>\vec{h}<em>i’ &#x3D; \sigma\left(\sum</em>{j \in N_i} \alpha_{i,j} W \vec{h}_j\right)<br>$$<br>其中 $\sigma$ 是非线性激活函数（如 ReLU）。</p><p>通过这一机制，图注意力网络能够显式建模节点间关系，适用于节点分类、链接预测等任务。</p><h3 id="DiffPool-详解：层次化图池化赋能图分类任务"><a href="#DiffPool-详解：层次化图池化赋能图分类任务" class="headerlink" title="DiffPool 详解：层次化图池化赋能图分类任务"></a><strong>DiffPool 详解：层次化图池化赋能图分类任务</strong></h3><h4 id="背景与问题"><a href="#背景与问题" class="headerlink" title="背景与问题"></a><strong>背景与问题</strong></h4><p>传统的图分类方法通常在图神经网络（GNN）后接全局池化（如求和、平均等），将所有节点嵌入压缩为一个向量。然而，这种做法忽略了图中潜在的<strong>层级结构</strong>，例如分子中的官能团或社交网络中的社区，导致模型难以捕捉多层次特征。<strong>DiffPool</strong>（Differentiable Pooling）由斯坦福团队提出，通过<strong>可微的层次化池化</strong>，逐步将细粒度节点聚合成粗粒度簇，构建多层抽象表示，显著提升图分类性能。</p><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><strong>核心思想</strong></h3><p>DiffPool 的核心是<strong>逐层粗化图结构</strong>，每层包含两个关键操作：</p><ol><li><strong>分配矩阵生成</strong>：动态决定当前层节点如何分配到下一层的簇。</li><li><strong>图结构更新</strong>：根据分配结果，生成下一层的节点特征和邻接矩阵。</li></ol><p>通过堆叠多层，图从局部到全局的层级特征被逐层提取，最终通过顶层全局池化得到图的整体表示。</p><h3 id="分层池化步骤"><a href="#分层池化步骤" class="headerlink" title="分层池化步骤"></a><strong>分层池化步骤</strong></h3><h4 id="1-分配矩阵生成（关键：可微与动态）"><a href="#1-分配矩阵生成（关键：可微与动态）" class="headerlink" title="1. 分配矩阵生成（关键：可微与动态）"></a><strong>1. 分配矩阵生成（关键：可微与动态）</strong></h4><p>• <strong>输入</strong>：当前层的节点特征 $X^{(l)} \in \mathbb{R}^{N_l \times d}$ 和邻接矩阵 $A^{(l)} \in \mathbb{R}^{N_l \times N_l}$（$N_l$ 为当前层节点数）。</p><p>• <strong>过程</strong>：使用一个独立的GNN（称为 <strong>GNN_pool</strong>）生成分配矩阵 $S^{(l)} \in \mathbb{R}^{N_l \times N_{l+1}}$，其中 $N_{l+1}$ 是下一层的簇数：<br>$$<br>S^{(l)} &#x3D; \text{softmax}\left(\text{GNN}_\text{pool}(X^{(l)}, A^{(l)})\right)<br>$$<br>  • <strong>softmax</strong> 按行归一化，确保每个节点分配到各簇的概率和为1。</p><p>  • <strong>GNN_pool</strong> 学习节点到簇的映射关系，例如通过注意力机制或消息传递。</p><h4 id="2-节点特征聚合（粗化特征）"><a href="#2-节点特征聚合（粗化特征）" class="headerlink" title="2. 节点特征聚合（粗化特征）"></a><strong>2. 节点特征聚合（粗化特征）</strong></h4><p>• <strong>下一层节点特征</strong>：将当前层特征按簇加权聚合：<br>$$<br>X^{(l+1)} &#x3D; {S^{(l)}}^T \cdot \left(\text{GNN}_\text{embed}(X^{(l)}, A^{(l)})\right)<br>$$<br>  • <strong>GNN_embed</strong>：另一个GNN，用于更新节点特征，增强当前层的表示能力。</p><p>  • ${S^{(l)}}^T \cdot (\cdot)$ 表示按簇分配权重求和，得到粗粒度特征。</p><h4 id="3-邻接矩阵更新（粗化连接）"><a href="#3-邻接矩阵更新（粗化连接）" class="headerlink" title="3. 邻接矩阵更新（粗化连接）"></a><strong>3. 邻接矩阵更新（粗化连接）</strong></h4><p>• <strong>下一层邻接矩阵</strong>：计算簇之间的连接强度：<br>$$<br>  A^{(l+1)} &#x3D; {S^{(l)}}^T \cdot A^{(l)} \cdot S^{(l)}<br>$$<br>  • 若原图中节点 $i$ 和 $j$ 相连，则它们所属的簇 $c_i$ 和 $c_j$ 的连接强度累加 $S_{i,c_i} \cdot A_{i,j} \cdot S_{j,c_j}$。</p><h3 id="训练与优化"><a href="#训练与优化" class="headerlink" title="训练与优化"></a><strong>训练与优化</strong></h3><p>• <strong>端到端训练</strong>：所有GNN（GNN_pool 和 GNN_embed）与分类器共同训练。<br>• <strong>正则化项</strong>：<br>  • <strong>链路预测损失</strong>：鼓励相邻节点分配到同一簇：<br>    $$<br>    \mathcal{L}<em>\text{LP} &#x3D; | A^{(l)} - S^{(l)} \cdot {S^{(l)}}^T |<em>F<br>    $$<br>  • <strong>熵正则化</strong>：防止分配矩阵过于稀疏或稠密：<br>    $$<br>    \mathcal{L}<em>\text{Entropy} &#x3D; -\frac{1}{N_l} \sum</em>{i&#x3D;1}^{N_l} \sum</em>{c&#x3D;1}^{N</em>{l+1}} S_{i,c}^{(l)} \log S_{i,c}^{(l)}<br>    $$<br>• <strong>总损失</strong>：分类损失 + $\lambda_1 \mathcal{L}_\text{LP} + \lambda_2 \mathcal{L}_\text{Entropy}$。</p><h3 id="示例流程"><a href="#示例流程" class="headerlink" title="示例流程"></a><strong>示例流程</strong></h3><p>以分子图分类为例（层级：原子 → 官能团 → 分子）：</p><ol><li><strong>第1层</strong>：原始原子节点，GNN提取原子特征。</li><li><strong>第1次池化</strong>：GNN_pool 将原子分配到官能团簇，生成粗化特征和邻接矩阵。</li><li><strong>第2层</strong>：官能团作为节点，GNN学习官能团间相互作用。</li><li><strong>第2次池化</strong>：进一步聚合成分子整体表示，输入分类器预测标签。</li></ol><h3 id="优势与挑战"><a href="#优势与挑战" class="headerlink" title="优势与挑战"></a><strong>优势与挑战</strong></h3><p>• <strong>优势</strong>：<br>  • <strong>层次化表示</strong>：显式建模图的层级结构，适合复杂图数据。<br>  • <strong>端到端可微</strong>：无需预定义池化规则，适应多种任务。<br>  • <strong>灵活整合</strong>：可与任意GNN架构（如GCN、GAT）结合。</p><p>• <strong>挑战</strong>：<br>  • <strong>计算开销</strong>：矩阵乘法复杂度为 $O(N^2)$，大规模图受限。<br>  • <strong>超参数敏感</strong>：需预设每层簇数 $N_{l+1}$，影响模型表现。<br>  • <strong>训练稳定性</strong>：多任务损失需精细调参。</p>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;title-”图神经网络”data-2025-3-5author-”朱宇阳”&quot;&gt;&lt;a href=&quot;#title-”图神经网络”data-2025-3-5author-”朱宇阳”&quot; class=&quot;headerlink&quot; title=&quot;title:”图神经网络”data:2025-3-5author:”朱宇阳”&quot;&gt;&lt;/a&gt;title:”图神经网络”&lt;br&gt;data:2025-3-5&lt;br&gt;author:”朱宇阳”&lt;/h2&gt;&lt;p&gt;深度学习-图神经网络学习笔记,欢迎访问我的&lt;a href=&quot;https://yuyangzhu7.github.io/&quot;&gt;主页&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://yuyangzhu7.github.io/2025/03/05/VLA%20%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/"/>
    <id>https://yuyangzhu7.github.io/2025/03/05/VLA%20%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/</id>
    <published>2025-03-05T05:00:33.399Z</published>
    <updated>2025-03-05T08:20:29.160Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title:”VLA学习”<br>data:2025-3-5<br>author&#x3D;朱宇阳</p><hr><p>今日份论文阅读！</p><p>参考：<br>1.<a href="https://arxiv.org/pdf/2503.01785">Visual-RFT</a></p><span id="more"></span> <p>视觉-语言-行动模型 （VLA） 代表了一类旨在处理多模态输入的模型，结合了来自视觉、语言和动作模态的信息。VLA 的开发是为了解决具身 AI 的指令遵循任务。具身 AI 需要控制物理体现并与环境交互.</p><p>在语言条件反射的机器人任务中，策略要求解语言指令&#x2F;视觉感知环境&#x2F;生成动作，即多模态能力。</p><p>1.深度学习早期发展：单峰模型</p><p><strong>AlexNet $\rightarrow$ RNN $\rightarrow$Transformers $\rightarrow$ANN</strong></p><p>2.基于强化学习的传统机器人:策略主要集中在一组有限的任务上,通常在工厂和实验室等受控环境中然而(S. Levine, P. Pastor, A. Krizhevsky, and D. Quillen, “Learning handeye coordination for robotic grasping with large-scale data collection,” in ISER, ser. Springer Proce)</p><blockquote><h3 id="1-One-Hot-向量的局限性"><a href="#1-One-Hot-向量的局限性" class="headerlink" title="1. One-Hot 向量的局限性"></a><strong>1. One-Hot 向量的局限性</strong></h3><h4 id="1-维度灾难"><a href="#1-维度灾难" class="headerlink" title="(1) 维度灾难"></a><strong>(1) 维度灾难</strong></h4><ul><li><strong>问题本质</strong>：<br> 每个任务被编码为一个独立的二进制维度（如任务1对应 <code>[1,0,0,...]</code>，任务2对应 <code>[0,1,0,...]</code>）。当任务数 <em>N</em> 极大时（如1000+），向量维度需扩展至 <em>N</em>，导致以下问题：</li><li><strong>存储成本激增</strong>：<br> 需要存储 <em>N</em> 维向量，内存占用随 <em>N</em> 线性增长。例如，1000个任务需1000个维度，10,000个任务需10,000个维度。</li><li><strong>计算效率下降</strong>：<br> 模型参数规模随维度线性增长（如全连接层的权重矩阵规模为 <em>H</em>×<em>N</em>，<em>H</em> 为隐藏层神经元数），训练速度显著降低。</li><li><strong>过拟合风险</strong>：<br> 模型容易将任务ID的独热编码本身当作特征学习（而非任务本质规律），导致在新任务上表现差。</li></ul><h4 id="2-任务间关系丢失"><a href="#2-任务间关系丢失" class="headerlink" title="(2) 任务间关系丢失"></a><strong>(2) 任务间关系丢失</strong></h4><ul><li>问题本质:One-Hot向量无法编码任务之间的语义关联。例如：</li><li>“图像分类” 和 “目标检测” 均属于计算机视觉任务，具有相关性；</li><li>“翻译” 和 “摘要” 均属于自然语言处理任务，但语义不同。</li><li><strong>后果</strong>：<br> 模型无法利用任务间的相似性迁移知识（如用图像分类模型辅助目标检测），也难以泛化到未见过但相关的任务。</li></ul><hr><h3 id="2-替代方案：任务嵌入（Task-Embedding）"><a href="#2-替代方案：任务嵌入（Task-Embedding）" class="headerlink" title="2. 替代方案：任务嵌入（Task Embedding）"></a><strong>2. 替代方案：任务嵌入（Task Embedding）</strong></h3><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><strong>核心思想</strong></h4><p>将离散的任务标识符（如任务ID）映射到<strong>低维连续空间</strong>（如512维）。相似任务在向量空间中距离较近，差异较大的任务距离较远。</p><h4 id="关键优势"><a href="#关键优势" class="headerlink" title="关键优势"></a><strong>关键优势</strong></h4><ul><li><strong>维度可控</strong>：<br> 固定低维（如256~512维），显著减少参数量和存储需求。</li><li><strong>捕捉语义关系</strong>：<br> 通过向量距离反映任务相关性（如 “猫” 和 “狗” 的嵌入向量相近）。</li><li><strong>动态扩展性</strong>：<br> 新任务可直接映射到已有连续空间，无需预留固定维度。</li></ul></blockquote><p>视觉编码器帮VLA 感知复杂的环境 ，提供估计，例如对象类别、对象姿势和对象几何形状。</p><p>集成视觉模型和语言模型的方法: BLIP-2 、Flamingo。</p><p>。一些 VLA 努力通过采用专为机器人任务设计的预训练任务来增强其预训练的视觉表示，主要重点是获得改进的视觉编码器。</p><p>与此同时，大量工作致力于机器人控制政策。在此类别中，语言指令被输入到控制策略中，该策略根据环境生成动作。相比之下，</p><p>另一类 VLA 充当高级任务规划器，抽象出低级控制。相反，这些模型专注于将长期机器人任务分解为子任务。然后，这些子任务可以通过控制策略逐个完成，最终完成整个任务。</p><p><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741076628530.png" alt="1741076628530"></p><p>我们介绍了当前机器人系统中层次结构的分类法，包括三个主要组件：预训练、控制策略和任务规划器。</p><p>预训练技术旨在增强 VLA 的特定方面，例如视觉编码器或动力学模型。</p><p>低级别控制策略根据指定的语言命令和感知的环境执行低级别作。</p><p>高级任务规划器将长距离任务分解为可由控制策略执行的子任务。</p><h2 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h2><h3 id="A-Unimodal-Models"><a href="#A-Unimodal-Models" class="headerlink" title="A. Unimodal Models"></a>A. Unimodal Models</h3>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;p&gt;title:”VLA学习”&lt;br&gt;data:2025-3-5&lt;br&gt;author&amp;#x3D;朱宇阳&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;今日份论文阅读！&lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;1.&lt;a href=&quot;https://arxiv.org/pdf/2503.01785&quot;&gt;Visual-RFT&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>前沿论文阅读</title>
    <link href="https://yuyangzhu7.github.io/2025/03/05/%E5%89%8D%E6%B2%BF%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>https://yuyangzhu7.github.io/2025/03/05/%E5%89%8D%E6%B2%BF%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</id>
    <published>2025-03-04T16:00:00.000Z</published>
    <updated>2025-03-05T13:43:00.676Z</updated>
    
    <content type="html"><![CDATA[<p>今日份论文阅读！</p><p>参考：<br>1.<a href="https://arxiv.org/pdf/2503.01785">Visual-RFT</a><br>2.<a href="https://arxiv.org/abs/2502.19645">Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success</a><br>3.<a href="https://arxiv.org/abs/2412.08635">LatentLM-Multimodal Latent Language Modeling with Next-Token Diffusion</a></p><span id="more"></span> <h1 id="LatentLM-Multimodal-Latent-Language-Modeling-with-Next-Token-Diffusion"><a href="#LatentLM-Multimodal-Latent-Language-Modeling-with-Next-Token-Diffusion" class="headerlink" title="LatentLM-Multimodal Latent Language Modeling with Next-Token Diffusion"></a>LatentLM-Multimodal Latent Language Modeling with Next-Token Diffusion</h1><p>本文通过在传统的<a href="https://zhida.zhihu.com/search?content_id=251479695&content_type=Article&match_order=1&q=causal+transformer&zhida_source=entity">causal transformer</a>结构中引入diffusion实现对离散模态（语言）和连续模态（图像、音频）等的一致处理</p><blockquote><h3 id="1-Causal-Transformer（因果Transformer）"><a href="#1-Causal-Transformer（因果Transformer）" class="headerlink" title="1. Causal Transformer（因果Transformer）"></a><strong>1. Causal Transformer（因果Transformer）</strong></h3><ul><li><strong>核心思想</strong>：在Transformer结构中引入<strong>因果性约束</strong>，确保每个位置的输出仅依赖于前面已生成的位置（即自回归顺序）。</li><li><strong>关键机制</strong>：通过<strong>位置掩码（Position Masking）</strong> 实现。在自回归生成时，每个位置只能看到自身及左侧的位置信息，右侧位置被遮蔽（mask掉），防止信息泄漏。</li></ul><h3 id="2-tinuous-Vector（连续向量）"><a href="#2-tinuous-Vector（连续向量）" class="headerlink" title="2.tinuous Vector（连续向量）"></a><strong>2.tinuous Vector（连续向量）</strong></h3><ul><li><strong>基本概念</strong>：将离散符号（如文本中的单词）或原始连续数据（如图像像素、音频波形）映射到<strong>高维连续空间</strong>的向量表示。</li><li>目的：</li><li><strong>统一模态表示</strong>：使离散模态（语言）和连续模态（图像&#x2F;音频）能在同一模型中处理。</li><li><strong>降低计算复杂度</strong>：通过低维潜在空间（如VAE编码）压缩数据，减少计算量。</li></ul></blockquote><p>总体结构如下图所示</p><p><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741153891716.png" alt="1741153891716"></p><p>图 1：Latent Language Modeling （LatentLM） 使用因果 Transformer 无缝处理连续（例如图像、音频、视频）和离散（例如文本和代码）数据。我们引入了 next-token diffusion 来逐个自回归生成潜在向量。所提出的方法提供了一个通用的接口，统一了多模态的生成和理解。</p><p>多模态生成模型需要一种<strong>统一的建模方法</strong>来处理离散数据和连续数据。</p><p>以前的大多数系统都依赖于构建管道或调用外部工具。但是，很难对基于管道的方法执行端到端优化。模块之间的信息丢失也会限制性能。 为了在多模态大型语言模型中原生处理离散和连续的数据，有三个主要的研究方向。</p><h3 id="1-基于VQ-VAE的离散化方法"><a href="#1-基于VQ-VAE的离散化方法" class="headerlink" title="1. 基于VQ-VAE的离散化方法"></a><strong>1. 基于VQ-VAE的离散化方法</strong></h3><p><strong>核心思想</strong>：通过VQ-VAE将连续数据量化为离散代码，在自回归语言模型中统一建模为离散序列。<br><strong>代表工作</strong>：VQ-VAE、DALL-E、VQGAN等。<br><strong>流程</strong>：</p><ol><li><strong>编码阶段</strong>：使用VQ-VAE编码器将连续数据映射到离散的代码本（Codebook），生成离散代码序列。</li><li><strong>建模阶段</strong>：所有数据（包括原始离散数据）均作为离散token输入自回归模型（如GPT），通过预测下一个token进行训练。</li><li><strong>解码阶段</strong>：利用VQ-VAE解码器将离散代码重建为连续数据。</li></ol><p><strong>优势</strong>：</p><ul><li>统一离散和连续数据的表示，简化模型架构。</li><li>自回归模型在文本生成任务中表现成熟。</li></ul><p><strong>局限性</strong>：</p><ul><li><strong>量化损失</strong>：VQ-VAE的离散化过程导致信息丢失，形成生成质量的瓶颈。</li><li><strong>低压缩率</strong>：连续数据（如视频）离散化后序列过长，增加计算负担。</li><li><strong>生成效率</strong>：长序列生成需要逐步自回归预测，速度较慢。</li></ul><hr><h3 id="2-基于扩散模型的统一方法"><a href="#2-基于扩散模型的统一方法" class="headerlink" title="2. 基于扩散模型的统一方法"></a><strong>2. 基于扩散模型的统一方法</strong></h3><p><strong>核心思想</strong>：将离散数据整合到扩散模型的框架中，利用扩散过程统一生成连续和离散数据。<br><strong>代表工作</strong>：连续数据扩散模型（如DDPM）、离散扩散模型（如D3PM）。<br><strong>流程</strong>：</p><ol><li><strong>扩散过程</strong>：对输入数据逐步添加噪声（连续数据）或扰动（离散数据）。</li><li><strong>去噪训练</strong>：模型学习从噪声中恢复原始数据。</li><li><strong>统一生成</strong>：通过同一扩散框架生成多模态数据。</li></ol><p><strong>优势</strong>：</p><ul><li>扩散模型在连续数据生成（如图像、音频）上表现优异。</li><li>理论上可统一多模态生成流程。</li></ul><p><strong>局限性</strong>：</p><ul><li><strong>离散数据建模性能下降</strong>：文本等离散数据需依赖自回归或掩码预测机制，扩散框架可能不如传统语言模型高效,其本身不是为了离散数据设计的。</li><li><strong>训练目标冲突</strong>：连续数据的噪声添加与离散数据的扰动机制难以完全兼容，可能导致联合训练不稳定。</li></ul><hr><h3 id="3-共享参数但分治目标的混合方法"><a href="#3-共享参数但分治目标的混合方法" class="headerlink" title="3. 共享参数但分治目标的混合方法"></a><strong>3. 共享参数但分治目标的混合方法</strong></h3><p><strong>核心思想</strong>：共享模型主干参数，但针对不同数据类型采用不同训练目标（扩散去噪 vs. 自回归预测）。<br><strong>代表工作</strong>：UniDiffuser、Lumina等。<br><strong>流程</strong>：</p><ol><li><strong>参数共享</strong>：模型主干（如Transformer层）处理所有类型数据。</li><li>分治目标：<ul><li><strong>连续数据</strong>：使用扩散目标（双向注意力，逐步去噪）。</li><li><strong>离散数据</strong>：使用自回归目标（因果注意力，预测下一token）。</li></ul></li><li><strong>联合训练</strong>：交替优化两种目标，实现多模态生成。</li></ol><p><strong>优势</strong>：</p><ul><li>参数共享提升模型容量利用率。</li><li>灵活适应不同数据类型的生成需求。</li></ul><p><strong>局限性</strong>：</p><ul><li><strong>目标冲突</strong>：扩散去噪与自回归预测的目标差异可能导致优化方向不一致。</li><li><strong>架构复杂性</strong>：需同时支持双向和因果注意力，增加实现难度。</li><li><strong>可变长度序列限制</strong>：扩散模型的双向注意力难以处理动态生成的序列（如实时语音）。</li><li><strong>噪声干扰</strong>：扩散训练的噪声可能破坏离散数据的联合训练效果。</li></ul><h4 id="4-本文核心方法：Latent-Language-Modeling-LatentLM"><a href="#4-本文核心方法：Latent-Language-Modeling-LatentLM" class="headerlink" title="4. 本文核心方法：Latent Language Modeling (LatentLM)"></a><strong>4. 本文核心方法：Latent Language Modeling (LatentLM)</strong></h4><h5 id="1-统一建模框架"><a href="#1-统一建模框架" class="headerlink" title="(1) 统一建模框架"></a><strong>(1) 统一建模框架</strong></h5><p>LatentLM的核心目标是<strong>通过因果Transformer架构统一处理离散（如文本）和连续（如图像、音频）数据</strong>，其核心创新点包括：</p><ul><li><strong>潜在空间表示</strong>：使用VAE将连续数据映射为低维连续向量（Latent Vectors），与离散数据的词嵌入（Word Embedding）共享同一语义空间。</li><li><strong>Next-Token Diffusion</strong>：通过扩散模型自回归预测连续数据的潜在向量，与传统语言模型的Next-Token Prediction（Softmax）结合，实现多模态统一生成。</li><li><strong>σ-VAE</strong>：改进VAE的潜在空间分布，使其更适合自回归解码。</li></ul><h5 id="2-技术流程"><a href="#2-技术流程" class="headerlink" title="(2) 技术流程"></a><strong>(2) 技术流程</strong></h5><ol><li>输入处理：<ul><li><strong>离散数据（文本）</strong>：通过词嵌入转换为连续向量序列。</li><li><strong>连续数据（图像&#x2F;音频）</strong>：通过VAE编码为潜在向量序列。</li></ul></li><li>共享Transformer处理：<ul><li>所有模态的潜在向量输入同一因果Transformer，生成联合上下文表示。</li></ul></li><li>输出解码：<ul><li><strong>离散数据</strong>：使用Softmax Head预测下一个词。</li><li><strong>连续数据</strong>：使用Diffusion Head生成下一个潜在向量，并通过VAE解码器还原原始数据</li></ul></li></ol><p>实际实现中，过程如下：</p><p>atentLM的核心设计目标是通过一个统一的Transformer架构，同时支持离散（文本）和连续（图像&#x2F;音频）模态的生成。其实现流程分为以下步骤：</p><ol><li>离散数据（文本）处理：<ul><li>传统语言模型（LM）方式：输入文本序列→词嵌入→因果Transformer→LM Head预测下一个词。</li></ul></li><li>连续数据（图像）处理：<ul><li>VAE编码：图像→潜在向量→因果Transformer→Diffusion Head预测去噪后的潜在向量→VAE解码器重建图像。</li></ul></li></ol><p>整个过程通过<strong>共享的因果Transformer</strong>实现模态间信息交互，下图展示了这一流程：</p><p><img src="https://pic2.zhimg.com/v2-9c4fea9cb00c2f1517fbd3eac1e1beb3_1440w.jpg" alt="img"></p><p>其中文章使用的类似VAE结构与原始VAE略有不同，文章中固定了标准差，用于防止训练过程发生collapse。故loss由原本的(1)式转变为了(3)式</p><p>$$<br>maximize\quad \mathbb E_{q_{\phi} (z|x)}[\log p_{\psi}(x|z)-D_{KL}[q_{\phi} (z|x) || p(z)]<br>$$<br>$$<br>minimize ||\hat x-x||^2_2 +\beta ||\mu||^2_2<br>$$</p><h1 id="Visual-RFT-Visual-Reinforcement-Fine-Tuning"><a href="#Visual-RFT-Visual-Reinforcement-Fine-Tuning" class="headerlink" title="Visual-RFT: Visual Reinforcement Fine-Tuning"></a>Visual-RFT: Visual Reinforcement Fine-Tuning</h1><p>OpenAI o1 等大型<strong>推理模型</strong>中的强化微调 （RFT） 从其答案的反馈中学习，这在微调数据稀缺的应用程序中特别有用。具有可验证奖励的强化学习是再现 o1 的一个关键方向。在多模态领域的应用仍未得到充分探索。这项工作</p><ul><li><p>引入了视觉强化微调 （Visual-RFT），它进一步扩展了 RFT 在视觉任务上的应用领域。首先使用大型视觉语言模型 （LVLM） 生成多个响应，其中包含每个输入的推理标记和最终答案，</p></li><li><p>提出<strong>视觉感知可验证奖励函数</strong>通过策略优化算法（如组相对策略优化 （GRPO））来更新模型。</p></li><li><p>不同的感知任务设计了不同的可验证奖励函数，例如用于对象检测的交集 （IoU） 奖励。</p></li><li><p>与监督微调 （SFT） 相比，Visual-RFT 具有竞争力的性能和先进的泛化能力。</p></li></ul><h3 id="大型推理模型（LRMs）与强化微调（RFT）的深度解析"><a href="#大型推理模型（LRMs）与强化微调（RFT）的深度解析" class="headerlink" title="大型推理模型（LRMs）与强化微调（RFT）的深度解析"></a><strong>大型推理模型（LRMs）与强化微调（RFT）的深度解析</strong></h3><h4 id="1-大型推理模型（LRMs）的定义与核心能力"><a href="#1-大型推理模型（LRMs）的定义与核心能力" class="headerlink" title="1. 大型推理模型（LRMs）的定义与核心能力"></a><strong>1. 大型推理模型（LRMs）的定义与核心能力</strong></h4><p><strong>大型推理模型（LRMs）</strong> 是一类专注于复杂多步推理任务的前沿AI模型，其核心目标是通过<strong>延长“思考”时间</strong>（即增加推理步骤或优化内部决策机制）提升模型在数学证明、逻辑推理、代码生成等任务中的表现。典型代表如 <strong>OpenAI o1</strong>，其设计理念强调在生成最终答案前进行更深入的内部推理。</p><h5 id="关键特征："><a href="#关键特征：" class="headerlink" title="关键特征："></a><strong>关键特征</strong>：</h5><p>• <strong>多步推理能力</strong>：通过链式思考（Chain-of-Thought）、思维树（Tree-of-Thoughts）或自省机制（Self-Refinement）模拟人类的多步推理过程。<br>• <strong>模块化架构</strong>：可能包含推理模块（如符号逻辑引擎）与生成模块（如Transformer）的协同工作。<br>• <strong>延迟生成策略</strong>：在输出答案前执行多次内部计算或验证步骤。</p><hr><h4 id="2-强化微调（RFT）的核心机制"><a href="#2-强化微调（RFT）的核心机制" class="headerlink" title="2. 强化微调（RFT）的核心机制"></a><strong>2. 强化微调（RFT）的核心机制</strong></h4><p><strong>强化微调（RFT）</strong> 是一种针对预训练语言模型（LLMs）的高效微调方法，其核心思想是<strong>通过强化学习（RL）优化模型在特定任务中的表现，仅需少量样本即可实现领域适应</strong>。与传统RLHF（基于人类反馈的强化学习）相比，RFT的突破在于<strong>样本效率</strong>和<strong>规则驱动</strong>。</p><h5 id="RFT与传统RLHF的对比："><a href="#RFT与传统RLHF的对比：" class="headerlink" title="RFT与传统RLHF的对比："></a><strong>RFT与传统RLHF的对比</strong>：</h5><table><thead><tr><th><strong>维度</strong></th><th><strong>传统RLHF</strong></th><th><strong>RFT</strong></th></tr></thead><tbody><tr><td><strong>奖励来源</strong></td><td>基于人类偏好数据训练的奖励模型</td><td>由预定义规则直接计算（Verifiable Rewards）</td></tr><tr><td><strong>数据需求</strong></td><td>需大量标注的偏好数据（如数万条）</td><td>仅需少量任务样本（几十至几千条）</td></tr><tr><td><strong>适用场景</strong></td><td>通用任务（如对话安全性、创意生成）</td><td>领域特定任务（如数学解题、代码生成）</td></tr><tr><td><strong>可解释性</strong></td><td>低（依赖黑盒奖励模型）</td><td>高（奖励规则透明）</td></tr></tbody></table><h5 id="RFT实现步骤："><a href="#RFT实现步骤：" class="headerlink" title="RFT实现步骤："></a><strong>RFT实现步骤</strong>：</h5><ol><li><strong>任务定义</strong>：明确领域任务的输入输出格式（如数学问题→解题步骤→答案）。</li><li><strong>规则化奖励设计</strong>：将任务成功标准编码为可计算的奖励函数（如答案正确性、步骤规范性）。</li><li><strong>策略优化</strong>：通过PPO等RL算法，最大化模型输出在奖励函数下的得分。</li></ol><hr><h4 id="3-可验证奖励（Verifiable-Rewards）的技术创新"><a href="#3-可验证奖励（Verifiable-Rewards）的技术创新" class="headerlink" title="3. 可验证奖励（Verifiable Rewards）的技术创新"></a><strong>3. 可验证奖励（Verifiable Rewards）的技术创新</strong></h4><p><strong>可验证奖励</strong> 是复现类似o1模型的关键技术，其核心在于<strong>通过预定义规则直接计算强化学习中的奖励分数</strong>，而非依赖独立训练的奖励模型。这一方法在开源研究（如DeepSeek R1）中已被验证有效。</p><h5 id="典型应用场景："><a href="#典型应用场景：" class="headerlink" title="典型应用场景："></a><strong>典型应用场景</strong>：</h5><p>• <strong>数学推理</strong>：答案正确性可通过符号计算验证（如SymPy库自动评分）。<br>• <strong>代码生成</strong>：奖励基于代码能否通过测试用例（如LeetCode评测）。<br>• <strong>逻辑证明</strong>：奖励取决于推理步骤是否符合形式逻辑规则。</p><h5 id="技术优势："><a href="#技术优势：" class="headerlink" title="技术优势："></a><strong>技术优势</strong>：</h5><p>• <strong>减少数据依赖</strong>：无需收集人类偏好数据，降低标注成本。<br>• <strong>消除奖励模型偏差</strong>：直接使用确定性规则，避免奖励模型的预测误差。<br>• <strong>提升训练稳定性</strong>：规则化奖励提供明确的优化信号，加速收敛。</p><hr><h4 id="4-可验证奖励-vs-传统奖励模型"><a href="#4-可验证奖励-vs-传统奖励模型" class="headerlink" title="4. 可验证奖励 vs. 传统奖励模型"></a><strong>4. 可验证奖励 vs. 传统奖励模型</strong></h4><table><thead><tr><th><strong>对比项</strong></th><th><strong>传统奖励模型</strong></th><th><strong>可验证奖励</strong></th></tr></thead><tbody><tr><td><strong>训练数据</strong></td><td>需要人类标注的偏好数据（如A&#x2F;B测试结果）</td><td>无需额外数据，依赖预定义规则</td></tr><tr><td><strong>适用范围</strong></td><td>主观性任务（如文本流畅性、创意评分）</td><td>客观性任务（如数学、代码、科学问题）</td></tr><tr><td><strong>计算开销</strong></td><td>需额外训练和部署奖励模型</td><td>直接调用规则函数，无额外模型推理成本</td></tr><tr><td><strong>可迁移性</strong></td><td>跨任务泛化能力有限</td><td>规则可复用至同类任务（如不同编程语言代码生成）</td></tr></tbody></table><hr><h4 id="5-复现o1的技术路径：以DeepSeek-R1为例"><a href="#5-复现o1的技术路径：以DeepSeek-R1为例" class="headerlink" title="5. 复现o1的技术路径：以DeepSeek R1为例"></a><strong>5. 复现o1的技术路径：以DeepSeek R1为例</strong></h4><p>开源研究（如DeepSeek R1）揭示了复现o1的可能方向：<strong>将可验证奖励与多步推理架构结合</strong>。</p><h5 id="关键技术步骤："><a href="#关键技术步骤：" class="headerlink" title="关键技术步骤："></a><strong>关键技术步骤</strong>：</h5><ol><li><strong>架构设计</strong>：<br>• <strong>推理模块</strong>：集成符号计算库（如Wolfram Alpha API）或形式化验证工具。<br>• <strong>生成模块</strong>：基于Transformer的LLM，负责生成候选答案。<br>• <strong>验证模块</strong>：自动执行规则检查（如代码测试、数学验证）。</li><li><strong>训练流程</strong>：<br>• <strong>预训练</strong>：在通用语料上训练基础LLM。<br>• <strong>RFT微调</strong>：使用可验证奖励优化特定任务（如仅用100条数学题样本）。</li><li><strong>推理优化</strong>：<br>• <strong>延迟生成</strong>：模型生成中间步骤后，调用验证模块检查正确性，若失败则重新推理。<br>• <strong>自省机制</strong>：根据验证结果动态调整生成策略（如优先选择已验证正确的子步骤）。</li></ol><p>SFT 范式$\rightarrow$依赖于大量的训练数据</p><p>RFT $\rightarrow$评估模型的响应，根据它们是否正确调整，通过反复试验来学习</p><p>因此，RFT 在<strong>数据稀缺</strong>的领域特别有用 [7， 24]。</p><p>实现细节:</p><p>1.对于每个输入，Visual-RFT 使用大型视觉语言模型 （LVLM） 生成包含推理标记和最终答案的多个响应（轨迹）。</p><p>2.我们定义了特定于任务的、基于规则的可验证奖励函数，以指导策略优化，例如 GRPO [31]，以更新模型。例如，我们建议为对象检测任务提供交集与联合 （IoU） 奖励。我们的 Visual-RFT 与 SFT 形成鲜明对比，后者依赖于记住正确答案。</p><p>3.我们的方法将训练范式从 SFT 中的数据扩展转变为针对特定多模态任务量身定制的可变奖励函数的战略设计。如图 2 （c） 所示，可验证奖励和视觉感知能力（例如，检测、接地、分类）的协同组合使我们的模型能够在详细的推理过程的帮助下实现对新概念的快速和数据高效掌握。</p><p><img src="C:\Users\朱宇阳\AppData\Roaming\Typora\typora-user-images\1741163131790.png" alt="1741163131790"></p><h1 id="Fine-Tuning-Vision-Language-Action-Models-Optimizing-Speed-and-Success"><a href="#Fine-Tuning-Vision-Language-Action-Models-Optimizing-Speed-and-Success" class="headerlink" title="Fine-Tuning Vision-Language-Action Models:  Optimizing Speed and Success"></a>Fine-Tuning Vision-Language-Action Models:  Optimizing Speed and Success</h1><h3 id="一、研究背景与挑战"><a href="#一、研究背景与挑战" class="headerlink" title="一、研究背景与挑战"></a>一、研究背景与挑战</h3><ol><li><p><strong>VLAs的优势</strong>：<br>• 通过在大规模机器人数据集上微调预训练的视觉-语言模型，VLAs展现出强大的跨机器人&#x2F;任务泛化能力<br>• 具备优秀的语义理解和指令遵循能力</p></li><li><p><strong>现存核心问题</strong>：<br>• 微调是部署VLAs到新场景的关键，但缺乏有效方法论指导<br>• 直接沿用预训练策略未必最优，且缺乏替代方案的实证研究</p></li></ol><h3 id="二、现有技术局限性"><a href="#二、现有技术局限性" class="headerlink" title="二、现有技术局限性"></a>二、现有技术局限性</h3><ol><li><p><strong>参数微调困境</strong>：LoRA等参数高效方法虽节省计算资源，但自回归生成导致3-5Hz的低频响应，全量微调同样面临双臂操作任务中的性能瓶颈</p></li><li><p><strong>加速技术的局限</strong>：新型动作编码方案（如符号化处理）将速度提升2-13倍，但是仍存在显著延迟（如FAST方案750ms），难以满足高频控制需求（&gt;2550Hz）</p></li></ol><h3 id="三、本研究创新点"><a href="#三、本研究创新点" class="headerlink" title="三、本研究创新点"></a>三、本研究创新点</h3><h4 id="（一）三大核心设计维度"><a href="#（一）三大核心设计维度" class="headerlink" title="（一）三大核心设计维度"></a>（一）三大核心设计维度</h4><table><thead><tr><th>设计维度</th><th>选项对比</th><th>实验发现</th></tr></thead><tbody><tr><td>动作解码方式</td><td>自回归 vs 并行生成</td><td>并行解码+分块技术：速度提升&amp;成功率提高，输入输出更灵活</td></tr><tr><td>动作表征形式</td><td>离散 vs 连续</td><td>连续动作显著提升模型质量</td></tr><tr><td>学习目标函数</td><td>下一token预测&#x2F;L1回归&#x2F;扩散</td><td>L1回归兼具训练快、收敛优、推理速的特点，性能接近扩散方法</td></tr></tbody></table><h4 id="（二）关键技术突破"><a href="#（二）关键技术突破" class="headerlink" title="（二）关键技术突破"></a>（二）关键技术突破</h4><ol><li><strong>并行解码架构</strong>：<br>• 采用分块处理消除自回归等待时间<br>• 在保持精度前提下实现实时响应（推测可达毫秒级延迟）</li><li><strong>连续动作空间优化</strong>：<br>• 相比离散编码（如关节角度离散化），连续建模能更好捕捉平滑运动轨迹<br>• 特别适合机械臂这类需要精细控制的场景</li><li><strong>L1回归优势</strong>：<br>• 训练速度比扩散方法提升数倍<br>• 推理时无需迭代采样，直接输出确定性动作<br>• 在保证任务成功率的同时降低计算负载</li></ol><blockquote><h3 id="二、L1回归——让机器人学会“直接回答问题”"><a href="#二、L1回归——让机器人学会“直接回答问题”" class="headerlink" title="二、L1回归——让机器人学会“直接回答问题”"></a>二、<strong>L1回归</strong>——让机器人学会“直接回答问题”</h3><h4 id="1-传统生成式方法（如GPT）的痛点"><a href="#1-传统生成式方法（如GPT）的痛点" class="headerlink" title="1. 传统生成式方法（如GPT）的痛点"></a>1. <strong>传统生成式方法（如GPT）的痛点</strong></h4><p>  • <strong>问题</strong>：当用语言模型预测动作时，模型会像聊天一样逐字生成（比如先预测“向前走”，再预测“右转”）。<br>  • <strong>缺陷</strong>：<br>    ◦ <strong>低频响应</strong>：每一步都要等待前一步生成，导致动作频率低下（如每秒只能生成几步）。<br>    ◦ <strong>随机性干扰</strong>：生成的动作可能包含不合理的小概率选项（比如“跳跃着拿杯子”）。</p><h4 id="2-L1回归的核心思想"><a href="#2-L1回归的核心思想" class="headerlink" title="2. L1回归的核心思想"></a>2. <strong>L1回归的核心思想</strong></h4><p>  • <strong>目标</strong>：把动作预测变成一个“填空题”而非“作文题”。<br>    ◦ 传统生成式模型：模型需要写出完整的动作序列（如“向前走→右转→拿起杯子”）。<br>    ◦ L1回归：直接给模型一个空白（如“<em>→_→_”），让它填入正确的动作数值（如[0.5m&#x2F;s, 30°, 0.2N]）。<br>  • <strong>数学表达</strong>：<br>    $$<br>    \text{Loss} &#x3D; \sum</em>{t&#x3D;1}^T | \hat{a}_t - a_t^{\text{true}} |_1<br>    $$<br>    → 目标是最小化预测动作$\hat{a}_t$与真实动作$a_t^{\text{true}}$的绝对误差之和。</p></blockquote><h3 id="三、方法创新：OpenVLA-OFT与OFT-框架"><a href="#三、方法创新：OpenVLA-OFT与OFT-框架" class="headerlink" title="三、方法创新：OpenVLA-OFT与OFT+框架"></a>三、方法创新：OpenVLA-OFT与OFT+框架</h3><h4 id="（一）核心技术集成"><a href="#（一）核心技术集成" class="headerlink" title="（一）核心技术集成"></a>（一）核心技术集成</h4><ol><li><strong>并行解码 + 动作分块</strong></li></ol><ul><li><strong>技术原理</strong>：打破传统自回归生成顺序依赖，通过分块处理允许并行计算多个动作片段</li><li>优势：<ul><li>推理延迟降低至毫秒级（如25步分块实现43×加速）</li><li>输入输出灵活性增强（支持非固定长度动作序列）</li></ul></li></ul><ol><li><strong>连续动作表征</strong><ul><li>采用高维连续空间（如关节角&#x2F;末端位姿）替代离散编码</li><li>关键价值：更好建模机械臂的平滑动力学特性，与物理引擎的闭环控制更兼容</li></ul></li><li><strong>L1回归目标函数</strong><ul><li>直接预测动作值而非语言模型的下一token</li><li>优化效益：训练速度提升3-5倍（对比扩散方法）。推理时无需迭代采样，确定性强</li></ul></li></ol><h4 id="（二）扩展方案OFT"><a href="#（二）扩展方案OFT" class="headerlink" title="（二）扩展方案OFT+"></a>（二）扩展方案OFT+</h4><ul><li>核心增强：引入FiLM（Feature-wise Linear Modulation）模块<ul><li><strong>功能</strong>：通过语言提示动态调制特征图，强化多模态语义对齐</li><li><strong>适用场景</strong>：需要精准理解复杂指令的真实世界任务</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;今日份论文阅读！&lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;1.&lt;a href=&quot;https://arxiv.org/pdf/2503.01785&quot;&gt;Visual-RFT&lt;/a&gt;&lt;br&gt;2.&lt;a href=&quot;https://arxiv.org/abs/2502.19645&quot;&gt;Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success&lt;/a&gt;&lt;br&gt;3.&lt;a href=&quot;https://arxiv.org/abs/2412.08635&quot;&gt;LatentLM-Multimodal Latent Language Modeling with Next-Token Diffusion&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>爬虫代码分享</title>
    <link href="https://yuyangzhu7.github.io/2025/02/20/%E7%88%AC%E8%99%AB%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB/"/>
    <id>https://yuyangzhu7.github.io/2025/02/20/%E7%88%AC%E8%99%AB%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB/</id>
    <published>2025-02-19T16:00:00.000Z</published>
    <updated>2025-03-04T07:42:14.920Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to my <a href="yuyangzhu7.github.io">page</a>! 本篇将介绍几种博主曾经撰写的爬虫代码,原创代码欢迎参考</p><span id="more"></span><h3 id="1-知乎个人主页爬取"><a href="#1-知乎个人主页爬取" class="headerlink" title="1.知乎个人主页爬取"></a>1.知乎个人主页爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.desired_capabilities <span class="keyword">import</span> DesiredCapabilities</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.service <span class="keyword">import</span> Service</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment"># 进入浏览器设置</span></span><br><span class="line">options = Options()</span><br><span class="line"><span class="comment"># 设置中文</span></span><br><span class="line">options.add_argument(<span class="string">&#x27;lang=zh_CN.UTF-8&#x27;</span>)</span><br><span class="line">options.add_experimental_option(<span class="string">&quot;excludeSwitches&quot;</span>,[<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line"><span class="comment"># 更换头部</span></span><br><span class="line">options.add_argument(</span><br><span class="line">    <span class="string">&#x27;user-agent=&quot;Mozilla/5.0 (iPod; U; CPU iPhone OS 2_1 like Mac OS X; ja-jp) AppleWebKit/525.18.1 (KHTML, like Gecko) Version/3.1.1 Mobile/5F137 Safari/525.20&quot;&#x27;</span>)</span><br><span class="line"><span class="comment"># get直接返回，不再等待界面加载完成</span></span><br><span class="line">desired_capabilities = DesiredCapabilities.CHROME</span><br><span class="line">desired_capabilities[<span class="string">&quot;pageLoadStrategy&quot;</span>] = <span class="string">&quot;none&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置Service对象</span></span><br><span class="line">service = Service(<span class="string">&quot;D:/anaconda/Scripts/chromedriver.exe&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化WebDriver</span></span><br><span class="line">driver = webdriver.Chrome(options=options)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">url = <span class="string">&quot;https://www.zhihu.com/people/ta-mei-yu-zhi-jian-de-wen-rou/answers&quot;</span></span><br><span class="line">driver.get(url)</span><br><span class="line">time.sleep(<span class="number">10</span>)</span><br><span class="line">page_sourse = driver.page_source</span><br><span class="line"></span><br><span class="line"><span class="comment">#正则化处理提取回答链接</span></span><br><span class="line">a = <span class="string">&#x27;&lt;a target=&quot;_blank&quot; data-za-detail-view-element_name=&quot;Title&quot; href=&quot;(.*?)&quot;&gt;&#x27;</span></span><br><span class="line"><span class="comment">#正则化处理提取回答问题名和回答者id</span></span><br><span class="line">a2=<span class="string">&#x27;&lt;meta itemprop=&quot;name&quot; content=&quot;(.*?)&quot;&gt;&#x27;</span></span><br><span class="line"><span class="comment">#正则化处理提取回答赞同数</span></span><br><span class="line">a3=<span class="string">&#x27;&lt;span&gt;&lt;button aria-label=&quot;(.*?)&quot; aria-live=&quot;polite&quot; type=&quot;button&quot; class=&quot;Button VoteButton VoteButton--up FEfUrdfMIKpQDJDqkjte&quot;&gt;&#x27;</span></span><br><span class="line"><span class="comment">#正则化处理提取回答时间</span></span><br><span class="line">a5=<span class="string">&#x27;&lt;meta itemprop=&quot;dateModified&quot; content=&quot;(.*?)&quot;&gt;&#x27;</span></span><br><span class="line">a = re.findall(a, page_sourse)</span><br><span class="line">a2 = re.findall(a2, page_sourse)</span><br><span class="line">a3=re.findall(a3,page_sourse)</span><br><span class="line">a5=re.findall(a5,page_sourse)</span><br><span class="line">question_names=a2[<span class="number">0</span>::<span class="number">2</span>]</span><br><span class="line">author_ids=a2[<span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line">time=a5</span><br><span class="line">answer_ids = [re.search(<span class="string">r&#x27;/answer/(\d+)&#x27;</span>, url).group(<span class="number">1</span>) <span class="keyword">for</span> url <span class="keyword">in</span> a]</span><br><span class="line">driver.quit()</span><br><span class="line"><span class="comment"># 通过下标访问数组中的元素</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(answer_ids)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;ID[<span class="subst">&#123;i&#125;</span>] = <span class="subst">&#123;answer_ids[i]&#125;</span>&quot;</span>)<span class="comment">#输出回答id</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = [(index, line.lstrip(<span class="string">&#x27;//&#x27;</span>)) <span class="keyword">for</span> index, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(a, <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">Line=[]<span class="comment">#回答链接列表</span></span><br><span class="line">answercontent=[]<span class="comment">#回答内容列表</span></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="keyword">for</span> index, line <span class="keyword">in</span> url:</span><br><span class="line">    Line.append(line)</span><br><span class="line"></span><br><span class="line">driver.quit()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义保存结果的文件名</span></span><br><span class="line">result_file = <span class="string">&#x27;zhihu_comments.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义空的DataFrame对象，用来存储所有的评论数据</span></span><br><span class="line">df_all = pd.DataFrame()</span><br><span class="line">comment_number=[]</span><br><span class="line"><span class="comment"># 循环遍历所有的回答id，通过第二种爬取方式获得评论内容</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(answer_ids)):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义目标回答的id</span></span><br><span class="line">    answer_id = answer_ids[i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义存储数据的列表</span></span><br><span class="line">    comments = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义初始的偏移量</span></span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义循环标志</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构造请求url，根据偏移量和回答id</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">f&#x27;https://www.zhihu.com/api/v4/answers/<span class="subst">&#123;answer_id&#125;</span>/comments?include=data%5B*%5D.author%2Ccollapsed%2Creply_to_author%2Cdisliked%2Ccontent%2Cvote_count%2Cis_parent_author%2Cis_author&amp;order=normal&amp;limit=20&amp;offset=<span class="subst">&#123;offset&#125;</span>&amp;status=open&#x27;</span></span><br><span class="line">    <span class="comment"># 发送请求，获取响应</span></span><br><span class="line">    response = requests.get(url, headers=headers)</span><br><span class="line">    <span class="comment"># 判断响应状态码是否为200</span></span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="comment"># 解析响应数据为json格式</span></span><br><span class="line">        data = response.json()</span><br><span class="line">        <span class="comment"># 获取评论列表</span></span><br><span class="line">        comments_list = data[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">        comment_count = data[<span class="string">&#x27;paging&#x27;</span>][<span class="string">&#x27;totals&#x27;</span>]</span><br><span class="line">        <span class="comment"># 判断评论列表是否为空</span></span><br><span class="line">        <span class="keyword">if</span> comments_list:</span><br><span class="line">            <span class="comment"># 遍历评论列表，提取需要的字段</span></span><br><span class="line">            <span class="keyword">for</span> comment <span class="keyword">in</span> comments_list:</span><br><span class="line">                <span class="comment"># 获取评论id</span></span><br><span class="line">                comment_id = comment[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">                <span class="comment"># 获取评论内容</span></span><br><span class="line">                content = comment[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">                <span class="comment"># 获取评论作者的姓名</span></span><br><span class="line">                author_name = comment[<span class="string">&#x27;author&#x27;</span>][<span class="string">&#x27;member&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">                <span class="comment"># 获取评论作者的性别，0为女，1为男，-1为未知</span></span><br><span class="line">                author_gender = comment[<span class="string">&#x27;author&#x27;</span>][<span class="string">&#x27;member&#x27;</span>][<span class="string">&#x27;gender&#x27;</span>]</span><br><span class="line">                <span class="comment"># 获取评论的点赞数</span></span><br><span class="line">                vote_count = comment[<span class="string">&#x27;vote_count&#x27;</span>]</span><br><span class="line">                <span class="comment"># 获取评论的创建时间，为10位时间戳</span></span><br><span class="line">                created_time = datetime.utcfromtimestamp(comment[<span class="string">&#x27;created_time&#x27;</span>])<span class="comment">#时间处理函数，将时间戳处理为24小时制时间</span></span><br><span class="line">                <span class="comment"># 获取评论id属地</span></span><br><span class="line">                address_text = comment[<span class="string">&#x27;address_text&#x27;</span>]</span><br><span class="line">                <span class="comment">#获取评论者id</span></span><br><span class="line">                author_id = comment[<span class="string">&#x27;author&#x27;</span>][<span class="string">&#x27;member&#x27;</span>][<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">                <span class="comment"># 将提取的字段组成一个字典，添加到数据列表中</span></span><br><span class="line">                comments.append(&#123;</span><br><span class="line">                    <span class="string">&#x27;回答id&#x27;</span>:answer_ids[i],</span><br><span class="line">                    <span class="string">&#x27;评论id&#x27;</span>: comment_id,</span><br><span class="line">                    <span class="string">&#x27;评论内容&#x27;</span>: content,</span><br><span class="line">                    <span class="string">&#x27;昵称&#x27;</span>: author_name,</span><br><span class="line">                    <span class="string">&#x27;性别&#x27;</span>: author_gender,</span><br><span class="line">                    <span class="string">&#x27;点赞数&#x27;</span>: vote_count,</span><br><span class="line">                    <span class="string">&#x27;评论时间&#x27;</span>: created_time,</span><br><span class="line">                    <span class="string">&#x27;ip属地&#x27;</span>: address_text,</span><br><span class="line">                    <span class="string">&#x27;用户id&#x27;</span>:author_id</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;已爬取<span class="subst">&#123;comment_count&#125;</span>条评论&#x27;</span>)</span><br><span class="line">            comment_number.append(comment_count)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果评论列表为空，说明没有更多数据，结束循环</span></span><br><span class="line">            flag = <span class="literal">False</span></span><br><span class="line">            comment_count=<span class="number">0</span></span><br><span class="line">            comment_number.append(comment_count)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;已爬取<span class="subst">&#123;comment_count&#125;</span>条评论&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果响应状态码不为200，说明请求出错，结束循环</span></span><br><span class="line">        flag = <span class="literal">False</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请求失败&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>个问题爬取完成&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将每次爬取的评论数据转换为DataFrame对象</span></span><br><span class="line">    df = pd.DataFrame(comments)</span><br><span class="line">    <span class="comment"># 使用concat函数将其拼接到总的DataFrame对象中</span></span><br><span class="line">    df_all = pd.concat([df_all, df], ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i==<span class="built_in">len</span>(answer_ids)-<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(answer_ids)):</span><br><span class="line">            url1 = <span class="string">f&#x27;https://<span class="subst">&#123;Line[i]&#125;</span>&#x27;</span></span><br><span class="line">            response1 = requests.get(url1, headers=headers)</span><br><span class="line"></span><br><span class="line">            soup = BeautifulSoup(response1.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">            answer_content = [p.get_text() <span class="keyword">for</span> p <span class="keyword">in</span> soup.select(<span class="string">&#x27;span.RichText.ztext.CopyrightRichText-richText.css-olurbu p&#x27;</span>)]</span><br><span class="line">            answercontent.append(answer_content)</span><br><span class="line"><span class="comment"># 将总的DataFrame对象一次性保存为csv文件</span></span><br><span class="line">df_all.to_csv(result_file, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印保存结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;评论内容已保存为<span class="subst">&#123;result_file&#125;</span>&#x27;</span>)</span><br><span class="line">data=<span class="built_in">list</span>(<span class="built_in">zip</span>(answer_ids,a,question_names,author_ids,a3,time,comment_number,answercontent))</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;answer.csv&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> csvfile:</span><br><span class="line">    csv_writer=csv.writer(csvfile)</span><br><span class="line">    csv_writer.writerow([<span class="string">&#x27;回答id&#x27;</span>,<span class="string">&#x27;回答网址&#x27;</span>,<span class="string">&#x27;问答问题名&#x27;</span>,<span class="string">&#x27;回答者昵称&#x27;</span>,<span class="string">&#x27;赞同数&#x27;</span>,<span class="string">&#x27;回答时间&#x27;</span>,<span class="string">&#x27;评论数量&#x27;</span>,<span class="string">&#x27;回答内容&#x27;</span>])</span><br><span class="line">    csv_writer.writerows(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;博主回答内容已保存为answer.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="2-京东商铺爬取"><a href="#2-京东商铺爬取" class="headerlink" title="2.京东商铺爬取"></a>2.京东商铺爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> DrissionPage <span class="keyword">import</span> ChromiumOptions</span><br><span class="line">path =<span class="string">r&#x27;&quot;C:/Program Files/Google/Chrome/Application/chrome.exe&quot;&#x27;</span></span><br><span class="line">ChromiumOptions().set_browser_path(path).save()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> DrissionPage <span class="keyword">import</span> ChromiumPage</span><br><span class="line"><span class="keyword">from</span> DrissionPage.common <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">f=<span class="built_in">open</span>(<span class="string">&#x27;data2.csv&#x27;</span>,mode=<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">csv_writer=csv.DictWriter(f,fieldnames=[    </span><br><span class="line">    <span class="string">&#x27;标题&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;价格&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;链接&#x27;</span>,])</span><br><span class="line">csv_writer.writeheader()</span><br><span class="line"></span><br><span class="line">dp=ChromiumPage()</span><br><span class="line">dp.get(<span class="string">&#x27;https://www.jd.com/&#x27;</span>)</span><br><span class="line">dp.ele(<span class="string">&#x27;css:#key&#x27;</span>).<span class="built_in">input</span>(<span class="string">&#x27;郫县豆瓣酱&#x27;</span>)</span><br><span class="line">dp.ele(<span class="string">&#x27;css:#key&#x27;</span>).<span class="built_in">input</span>(Keys.ENTER)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">31</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;已经爬取到了第&#x27;</span>+<span class="built_in">str</span>(page)+<span class="string">&#x27;页\n&#x27;</span>)</span><br><span class="line">    dp.scroll.to_bottom()</span><br><span class="line">    lis=dp.eles(<span class="string">&#x27;css:.gl-item&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> lis:</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">#dp.scroll.down(50)</span></span><br><span class="line">            title=li.ele(<span class="string">&#x27;css:.p-name a em&#x27;</span>).text</span><br><span class="line">            price=li.ele(<span class="string">&#x27;css:.p-price i&#x27;</span>).text</span><br><span class="line">            href=li.ele(<span class="string">&#x27;css:.p-name a&#x27;</span>).attr(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;li.ele(&#x27;css:.p-name a em&#x27;).click() #进入新页面</span></span><br><span class="line"><span class="string">            tabs=dp.get_tabs()</span></span><br><span class="line"><span class="string">            tab=tabs[-1]</span></span><br><span class="line"><span class="string">            img=tab.ele(&#x27;css:#spec-img&#x27;).attr(&#x27;src&#x27;)</span></span><br><span class="line"><span class="string">            comment=tab.ele(&#x27;css:.comment-con&#x27;).text</span></span><br><span class="line"><span class="string">            tab.close()&#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="built_in">dict</span>=&#123;</span><br><span class="line">            <span class="string">&#x27;标题&#x27;</span>:title,</span><br><span class="line">            <span class="string">&#x27;价格&#x27;</span>:price,</span><br><span class="line">            <span class="string">&#x27;链接&#x27;</span>:href,</span><br><span class="line">            &#125;</span><br><span class="line">            csv_writer.writerow(<span class="built_in">dict</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="built_in">dict</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    lis[<span class="number">0</span>].<span class="built_in">input</span>(Keys.RIGHT)</span><br></pre></td></tr></table></figure><h3 id="3-京东评论爬取（可接2使用）"><a href="#3-京东评论爬取（可接2使用）" class="headerlink" title="3.京东评论爬取（可接2使用）"></a>3.京东评论爬取（可接2使用）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> DrissionPage <span class="keyword">import</span> ChromiumPage</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 `with open` 自动管理文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data4.csv&#x27;</span>, mode=<span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    csv_writer = csv.DictWriter(f, fieldnames=[<span class="string">&#x27;名称&#x27;</span>, <span class="string">&#x27;评论&#x27;</span>, <span class="string">&#x27;购买时间&#x27;</span>])</span><br><span class="line">    csv_writer.writeheader()</span><br><span class="line"></span><br><span class="line">    dp = ChromiumPage()</span><br><span class="line">    df = pd.read_csv(<span class="string">&#x27;data2.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;链接&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> df[<span class="string">&#x27;链接&#x27;</span>]:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                dp.get(url)</span><br><span class="line">                time.sleep(<span class="number">2</span>)</span><br><span class="line">                <span class="comment"># 等待页面主要内容加载，选取一个确定会加载的元素</span></span><br><span class="line">                <span class="comment">#dp.wait.ele(&#x27;css:#detail&#x27;, timeout=10)</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 滚动到底部，提高评论加载可能性</span></span><br><span class="line">                dp.scroll.to_bottom()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 确保“评论”选项卡可用后再点击</span></span><br><span class="line">                tab_element = dp.ele(<span class="string">&#x27;css:#detail &gt; div.tab-main.large &gt; ul &gt; li.current&#x27;</span>, timeout=<span class="number">5</span>)</span><br><span class="line">                <span class="keyword">if</span> tab_element:</span><br><span class="line">                    tab_element.click()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 监听网络请求，设置超时避免卡住</span></span><br><span class="line">                dp.listen.start(<span class="string">&#x27;pc_club_productPageComments&#x27;</span>)</span><br><span class="line">                r = dp.listen.wait(timeout=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> r:</span><br><span class="line">                    json_data = r.response.body</span><br><span class="line">                    <span class="built_in">print</span>(json_data)</span><br><span class="line"></span><br><span class="line">                    comments = json_data.get(<span class="string">&#x27;comments&#x27;</span>, [])</span><br><span class="line">                    <span class="keyword">for</span> index <span class="keyword">in</span> comments:</span><br><span class="line">                        row_data = &#123;</span><br><span class="line">                            <span class="string">&#x27;名称&#x27;</span>: index.get(<span class="string">&#x27;nickname&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>),</span><br><span class="line">                            <span class="string">&#x27;评论&#x27;</span>: index.get(<span class="string">&#x27;content&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>),</span><br><span class="line">                            <span class="string">&#x27;购买时间&#x27;</span>: index.get(<span class="string">&#x27;referenceTime&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>),</span><br><span class="line">                        &#125;</span><br><span class="line">                        csv_writer.writerow(row_data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;处理 <span class="subst">&#123;url&#125;</span> 时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Welcome to my &lt;a href=&quot;yuyangzhu7.github.io&quot;&gt;page&lt;/a&gt;! 本篇将介绍几种博主曾经撰写的爬虫代码,原创代码欢迎参考&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>个人主页</title>
    <link href="https://yuyangzhu7.github.io/2024/11/20/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5%E6%90%AD%E5%BB%BA/"/>
    <id>https://yuyangzhu7.github.io/2024/11/20/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5%E6%90%AD%E5%BB%BA/</id>
    <published>2024-11-19T16:00:00.000Z</published>
    <updated>2025-03-04T07:06:12.998Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to my <a href="yuyangzhu7.github.io">page</a>! 本篇将记录博主个人主页搭建的各种信息和相关方式，欢迎参考</p><span id="more"></span><h4 id="1-在标题前加入"><a href="#1-在标题前加入" class="headerlink" title="1.在标题前加入:"></a>1.在标题前加入:</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">title: &quot;个人主页&quot;</span><br><span class="line">date: 2024-11-20</span><br><span class="line">author: 朱宇阳</span><br></pre></td></tr></table></figure><p>并前后行用“—”包裹,进行基本信息概括</p><h4 id="2-加入-以对过长部分进行收缩和展开"><a href="#2-加入-以对过长部分进行收缩和展开" class="headerlink" title="2.加入&lt;!–more–&gt; 以对过长部分进行收缩和展开"></a>2.加入&lt;!–more–&gt; 以对过长部分进行收缩和展开</h4><h4 id="3-hexo常见命令"><a href="#3-hexo常见命令" class="headerlink" title="3.hexo常见命令"></a>3.hexo常见命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean #清除缓存文件 (db.json) 和已生成的静态文件 (public)。</span><br><span class="line">$ hexo generate   #生成静态文件。</span><br><span class="line">$ hexo server</span><br><span class="line">#启动服务器。默认情况下，访问网址为： http://localhost:4000/。</span><br><span class="line">$ hexo d #部署网站，构建在GitHub的服务器中。</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-d:                </span><br><span class="line">--deploy,文件生成后立即部署网站</span><br><span class="line">-w:</span><br><span class="line">--watch,监视文件变动</span><br><span class="line">-b:</span><br><span class="line">--bail,生成过程中如果发生任何未处理的异常则抛出异常</span><br><span class="line">-f</span><br><span class="line">:--force,强制重新生成文件. Hexo 引入了差分机制，如果 public 目录存在，那么 hexo g 只会重新生成改动的文件。 使用该参数的效果接近 hexo clean &amp;&amp; hexo generate</span><br><span class="line">-c</span><br><span class="line">:--concurrency,最大同时生成文件的数量，默认无限制</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>通常使用：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p> 其中 <code>hexo clean</code>清除了你之前生成的东西，也可以不加。 <code>hexo generate</code> 顾名思义，生成静态文章，可以用 <code>hexo g</code>缩写 <code>hexo deploy</code> 部署文章，可以用<code>hexo d</code>缩写 </p></blockquote><h4 id="4-使用主题"><a href="#4-使用主题" class="headerlink" title="4.使用主题"></a>4.使用主题</h4><p>主题为<strong>next</strong>，目录为**&#x2F;Desktop&#x2F;competition&#x2F;Yuyang_Zhu**</p><p>  blog文件夹（即根目录）下 <strong>themes文件夹，这个文件夹里面存放你下载的主题文件</strong>，可以看到next主题又再次包含一个文件夹，其中包含了next 主题的配置信息 </p><p>修改 博客的标题，副标题，描述，等等基本信息:在 blog根目录下打开 _config.yml 配置文件，直接修改即可</p><h4 id="5-参考学习链接："><a href="#5-参考学习链接：" class="headerlink" title="5.参考学习链接："></a>5.参考学习链接：</h4><p>Hexo+Next主题搭建个人博客+优化全过程（完整详细版）：<br><a href="https://zhuanlan.zhihu.com/p/618864711">https://zhuanlan.zhihu.com/p/618864711</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Welcome to my &lt;a href=&quot;yuyangzhu7.github.io&quot;&gt;page&lt;/a&gt;! 本篇将记录博主个人主页搭建的各种信息和相关方式，欢迎参考&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
